{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchsummary import summary\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from simple_movement import DataGen, SimpleMovement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dgen = DataGen(100, 100, 5)\n",
    "x, y = dgen.get_data('./data/data_simple_movement_1/', 10, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((120, 5, 100, 100), (120, 3))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MMC(nn.Module):\n",
    "    \n",
    "    def __init__(self, beta=5, num_iter=1):\n",
    "        super(MMC, self).__init__()\n",
    "        self.df = 1. / beta\n",
    "        self.num_iter = num_iter\n",
    "        self.weights = nn.Parameter(\n",
    "            data= torch.tensor([[1, self.df, 0], [-1, 0, 1], [0, 0, 1]]),\n",
    "            requires_grad=False\n",
    "        ) # .unsqueeze(0).expand(9, 3, 3)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        # = torch.bmm(torch.pow(self.weights, self.num_iter), x.unsqueeze(2)).squeeze(2)\n",
    "        x = torch.matmul(self.weights, x.transpose(0, 1))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_channel):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=num_channel, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 8, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(8, 8, 3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(8, 8, 2)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(200, 128)\n",
    "        self.fc2 = nn.Linear(128, 3)\n",
    "        self.mmc = MMC()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = self.pool(F.relu(self.conv4(x)))\n",
    "        x = x.view(-1, 5*5*8)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        print('before mmc: {}'.format(x))\n",
    "        x = self.mmc(x)\n",
    "        print('after mmc: {}\\n'.format(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight torch.Size([16, 1, 3, 3])\n",
      "conv1.bias torch.Size([16])\n",
      "conv2.weight torch.Size([8, 16, 3, 3])\n",
      "conv2.bias torch.Size([8])\n",
      "conv3.weight torch.Size([8, 8, 3, 3])\n",
      "conv3.bias torch.Size([8])\n",
      "conv4.weight torch.Size([8, 8, 2, 2])\n",
      "conv4.bias torch.Size([8])\n",
      "fc1.weight torch.Size([128, 200])\n",
      "fc1.bias torch.Size([128])\n",
      "fc2.weight torch.Size([3, 128])\n",
      "fc2.bias torch.Size([3])\n",
      "mmc.weights torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "model = Encoder(1)\n",
    "for n, p in model.named_parameters():\n",
    "    print(n, p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary(model, (1, 100, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(num_channel):\n",
    "    \n",
    "    net = Encoder(num_channel=num_channel)\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "    \n",
    "    return net, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tensor(x):\n",
    "    return torch.from_numpy(x).float()\n",
    "\n",
    "def get_data(height, width, num_channel, path, size, bs):\n",
    "    \n",
    "    dgen = DataGen(height, width, num_channel)\n",
    "    x, y = dgen.get_feature_target_pairs(path, size)\n",
    "    print('Data loaded...\\nx:{}\\ty:{}\\n'.format(x.shape, y.shape))\n",
    "    \n",
    "    x = x / 255.\n",
    "    x = x[:90]\n",
    "    y = y[:90]\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, shuffle=True, random_state=331)\n",
    "    x_train, x_test, y_train, y_test = map(to_tensor, (x_train, x_test, y_train, y_test))\n",
    "    \n",
    "    train_ds = TensorDataset(x_train, y_train)\n",
    "    train_dl = DataLoader(train_ds, batch_size=bs, shuffle=True)\n",
    "\n",
    "    test_ds = TensorDataset(x_test, y_test)\n",
    "    test_dl = DataLoader(test_ds, batch_size=bs)\n",
    "    \n",
    "    return train_dl, test_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_flow(named_parameters):\n",
    "    ave_grads = []\n",
    "    max_grads= []\n",
    "    layers = []\n",
    "    for n, p in named_parameters:\n",
    "        if(p.requires_grad) and (\"bias\" not in n):\n",
    "            layers.append(n)\n",
    "            ave_grads.append(p.grad.abs().mean())\n",
    "            max_grads.append(p.grad.abs().max())\n",
    "    print('layers: {}'.format(layers))\n",
    "    print('max: {}'.format(max_grads))\n",
    "    print('mean: {}\\n\\n'.format( ave_grads))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(net, optimizer, train_dl, test_dl, epochs=5):\n",
    "    \n",
    "    loss_function = nn.MSELoss()\n",
    "    for epoch in range(epochs):\n",
    "        net.train()\n",
    "        for x, y in train_dl:\n",
    "            pred = net(x)\n",
    "            loss = loss_function(pred, y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            grad_flow(net.named_parameters())\n",
    "            optimizer.step()\n",
    "\n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "            test_loss = sum(loss_function(net(x), y) for x, y in test_dl)\n",
    "        print('epoch:{}, test_loss:{}'.format(epoch+1, test_loss/len(test_dl)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded...\n",
      "x:(96, 2, 100, 100)\ty:(96, 3)\n",
      "\n",
      "before mmc: tensor([[-0.0213,  0.0899, -0.0765]], grad_fn=<AddmmBackward>)\n",
      "after mmc: tensor([[-0.0033],\n",
      "        [-0.0552],\n",
      "        [-0.0765]], grad_fn=<MmBackward>)\n",
      "\n",
      "layers: ['conv1.weight', 'conv2.weight', 'conv3.weight', 'conv4.weight', 'fc1.weight', 'fc2.weight']\n",
      "max: [tensor(0.1430), tensor(0.2257), tensor(0.1869), tensor(0.3095), tensor(0.2646), tensor(3.3810)]\n",
      "mean: [tensor(0.0233), tensor(0.0215), tensor(0.0147), tensor(0.0227), tensor(0.0238), tensor(0.2322)]\n",
      "\n",
      "\n",
      "before mmc: tensor([[-0.0213,  0.0990, -0.0473]], grad_fn=<AddmmBackward>)\n",
      "after mmc: tensor([[-0.0015],\n",
      "        [-0.0260],\n",
      "        [-0.0473]], grad_fn=<MmBackward>)\n",
      "\n",
      "layers: ['conv1.weight', 'conv2.weight', 'conv3.weight', 'conv4.weight', 'fc1.weight', 'fc2.weight']\n",
      "max: [tensor(0.1275), tensor(0.2933), tensor(0.1842), tensor(0.4965), tensor(0.2690), tensor(3.4809)]\n",
      "mean: [tensor(0.0245), tensor(0.0241), tensor(0.0203), tensor(0.0528), tensor(0.0228), tensor(0.2333)]\n",
      "\n",
      "\n",
      "before mmc: tensor([[-0.0214,  0.1090, -0.0175]], grad_fn=<AddmmBackward>)\n",
      "after mmc: tensor([[ 0.0004],\n",
      "        [ 0.0040],\n",
      "        [-0.0175]], grad_fn=<MmBackward>)\n",
      "\n",
      "layers: ['conv1.weight', 'conv2.weight', 'conv3.weight', 'conv4.weight', 'fc1.weight', 'fc2.weight']\n",
      "max: [tensor(0.1794), tensor(0.2735), tensor(0.1757), tensor(0.4013), tensor(0.1445), tensor(1.9268)]\n",
      "mean: [tensor(0.0238), tensor(0.0216), tensor(0.0167), tensor(0.0527), tensor(0.0109), tensor(0.1198)]\n",
      "\n",
      "\n",
      "before mmc: tensor([[-0.0204,  0.1196,  0.0118]], grad_fn=<AddmmBackward>)\n",
      "after mmc: tensor([[0.0035],\n",
      "        [0.0322],\n",
      "        [0.0118]], grad_fn=<MmBackward>)\n",
      "\n",
      "layers: ['conv1.weight', 'conv2.weight', 'conv3.weight', 'conv4.weight', 'fc1.weight', 'fc2.weight']\n",
      "max: [tensor(2.2649), tensor(3.7848), tensor(2.5479), tensor(4.6737), tensor(1.6947), tensor(23.1665)]\n",
      "mean: [tensor(0.2669), tensor(0.2810), tensor(0.2226), tensor(0.8557), tensor(0.1340), tensor(1.3704)]\n",
      "\n",
      "\n",
      "before mmc: tensor([[-0.0192,  0.1281,  0.0379]], grad_fn=<AddmmBackward>)\n",
      "after mmc: tensor([[0.0064],\n",
      "        [0.0571],\n",
      "        [0.0379]], grad_fn=<MmBackward>)\n",
      "\n",
      "layers: ['conv1.weight', 'conv2.weight', 'conv3.weight', 'conv4.weight', 'fc1.weight', 'fc2.weight']\n",
      "max: [tensor(1.5771), tensor(3.2485), tensor(2.2645), tensor(4.6099), tensor(1.2682), tensor(18.0406)]\n",
      "mean: [tensor(0.2034), tensor(0.2037), tensor(0.1834), tensor(0.7878), tensor(0.0956), tensor(1.0273)]\n",
      "\n",
      "\n",
      "before mmc: tensor([[-0.0150,  0.1377,  0.0668]], grad_fn=<AddmmBackward>)\n",
      "after mmc: tensor([[0.0125],\n",
      "        [0.0818],\n",
      "        [0.0668]], grad_fn=<MmBackward>)\n",
      "\n",
      "layers: ['conv1.weight', 'conv2.weight', 'conv3.weight', 'conv4.weight', 'fc1.weight', 'fc2.weight']\n",
      "max: [tensor(0.1886), tensor(0.4276), tensor(0.3563), tensor(0.6239), tensor(0.1619), tensor(2.4041)]\n",
      "mean: [tensor(0.0287), tensor(0.0276), tensor(0.0227), tensor(0.1079), tensor(0.0112), tensor(0.1352)]\n",
      "\n",
      "\n",
      "before mmc: tensor([[-0.0080,  0.1491,  0.0921]], grad_fn=<AddmmBackward>)\n",
      "after mmc: tensor([[0.0218],\n",
      "        [0.1001],\n",
      "        [0.0921]], grad_fn=<MmBackward>)\n",
      "\n",
      "layers: ['conv1.weight', 'conv2.weight', 'conv3.weight', 'conv4.weight', 'fc1.weight', 'fc2.weight']\n",
      "max: [tensor(2.3043), tensor(5.8402), tensor(5.5257), tensor(7.8628), tensor(2.0077), tensor(31.0025)]\n",
      "mean: [tensor(0.4133), tensor(0.3117), tensor(0.2964), tensor(1.3280), tensor(0.1297), tensor(1.7505)]\n",
      "\n",
      "\n",
      "before mmc: tensor([[-2.1268e-05,  1.6201e-01,  1.2036e-01]], grad_fn=<AddmmBackward>)\n",
      "after mmc: tensor([[0.0324],\n",
      "        [0.1204],\n",
      "        [0.1204]], grad_fn=<MmBackward>)\n",
      "\n",
      "layers: ['conv1.weight', 'conv2.weight', 'conv3.weight', 'conv4.weight', 'fc1.weight', 'fc2.weight']\n",
      "max: [tensor(0.6417), tensor(1.6463), tensor(1.7150), tensor(2.1073), tensor(0.5114), tensor(8.4020)]\n",
      "mean: [tensor(0.1217), tensor(0.0858), tensor(0.0800), tensor(0.3539), tensor(0.0332), tensor(0.4765)]\n",
      "\n",
      "\n",
      "before mmc: tensor([[0.0097, 0.1750, 0.1492]], grad_fn=<AddmmBackward>)\n",
      "after mmc: tensor([[0.0447],\n",
      "        [0.1395],\n",
      "        [0.1492]], grad_fn=<MmBackward>)\n",
      "\n",
      "layers: ['conv1.weight', 'conv2.weight', 'conv3.weight', 'conv4.weight', 'fc1.weight', 'fc2.weight']\n",
      "max: [tensor(1.4478), tensor(3.3758), tensor(4.3144), tensor(4.6456), tensor(1.0451), tensor(18.2509)]\n",
      "mean: [tensor(0.2604), tensor(0.1911), tensor(0.1826), tensor(0.7743), tensor(0.0682), tensor(1.0415)]\n",
      "\n",
      "\n",
      "before mmc: tensor([[0.0209, 0.1923, 0.1827]], grad_fn=<AddmmBackward>)\n",
      "after mmc: tensor([[0.0594],\n",
      "        [0.1618],\n",
      "        [0.1827]], grad_fn=<MmBackward>)\n",
      "\n",
      "layers: ['conv1.weight', 'conv2.weight', 'conv3.weight', 'conv4.weight', 'fc1.weight', 'fc2.weight']\n",
      "max: [tensor(2.0473), tensor(6.6684), tensor(8.8477), tensor(8.2679), tensor(1.6110), tensor(29.6406)]\n",
      "mean: [tensor(0.6442), tensor(0.3674), tensor(0.3887), tensor(1.2626), tensor(0.1156), tensor(1.7301)]\n",
      "\n",
      "\n",
      "before mmc: tensor([[0.0330, 0.2125, 0.2216]], grad_fn=<AddmmBackward>)\n",
      "after mmc: tensor([[0.0755],\n",
      "        [0.1886],\n",
      "        [0.2216]], grad_fn=<MmBackward>)\n",
      "\n",
      "layers: ['conv1.weight', 'conv2.weight', 'conv3.weight', 'conv4.weight', 'fc1.weight', 'fc2.weight']\n",
      "max: [tensor(1.9847), tensor(5.5580), tensor(8.9743), tensor(7.7278), tensor(1.2865), tensor(24.9387)]\n",
      "mean: [tensor(0.6164), tensor(0.3755), tensor(0.4116), tensor(1.0997), tensor(0.0990), tensor(1.4945)]\n",
      "\n",
      "\n",
      "before mmc: tensor([[0.0460, 0.2351, 0.2659]], grad_fn=<AddmmBackward>)\n",
      "after mmc: tensor([[0.0930],\n",
      "        [0.2199],\n",
      "        [0.2659]], grad_fn=<MmBackward>)\n",
      "\n",
      "layers: ['conv1.weight', 'conv2.weight', 'conv3.weight', 'conv4.weight', 'fc1.weight', 'fc2.weight']\n",
      "max: [tensor(2.5999), tensor(7.1056), tensor(11.2560), tensor(9.1069), tensor(1.3382), tensor(27.3131)]\n",
      "mean: [tensor(0.6766), tensor(0.5136), tensor(0.5457), tensor(1.2135), tensor(0.1030), tensor(1.6670)]\n",
      "\n",
      "\n",
      "before mmc: tensor([[0.0608, 0.2617, 0.3172]], grad_fn=<AddmmBackward>)\n",
      "after mmc: tensor([[0.1131],\n",
      "        [0.2564],\n",
      "        [0.3172]], grad_fn=<MmBackward>)\n",
      "\n",
      "layers: ['conv1.weight', 'conv2.weight', 'conv3.weight', 'conv4.weight', 'fc1.weight', 'fc2.weight']\n",
      "max: [tensor(4.6867), tensor(11.4540), tensor(24.7564), tensor(19.0086), tensor(2.4271), tensor(50.6441)]\n",
      "mean: [tensor(1.2517), tensor(0.8837), tensor(1.2338), tensor(2.4807), tensor(0.1915), tensor(3.2095)]\n",
      "\n",
      "\n",
      "before mmc: tensor([[0.0776, 0.2892, 0.3730]], grad_fn=<AddmmBackward>)\n",
      "after mmc: tensor([[0.1354],\n",
      "        [0.2953],\n",
      "        [0.3730]], grad_fn=<MmBackward>)\n",
      "\n",
      "layers: ['conv1.weight', 'conv2.weight', 'conv3.weight', 'conv4.weight', 'fc1.weight', 'fc2.weight']\n",
      "max: [tensor(2.8300), tensor(7.9668), tensor(12.8881), tensor(9.4214), tensor(1.0538), tensor(23.0543)]\n",
      "mean: [tensor(0.7909), tensor(0.4957), tensor(0.7199), tensor(1.2573), tensor(0.0848), tensor(1.4882)]\n",
      "\n",
      "\n",
      "before mmc: tensor([[0.0978, 0.3230, 0.4407]], grad_fn=<AddmmBackward>)\n",
      "after mmc: tensor([[0.1624],\n",
      "        [0.3429],\n",
      "        [0.4407]], grad_fn=<MmBackward>)\n",
      "\n",
      "layers: ['conv1.weight', 'conv2.weight', 'conv3.weight', 'conv4.weight', 'fc1.weight', 'fc2.weight']\n",
      "max: [tensor(1.5633), tensor(4.0233), tensor(6.3065), tensor(4.4813), tensor(0.4432), tensor(9.9923)]\n",
      "mean: [tensor(0.4448), tensor(0.2271), tensor(0.3672), tensor(0.6243), tensor(0.0354), tensor(0.6653)]\n",
      "\n",
      "\n",
      "before mmc: tensor([[0.1212, 0.3616, 0.5173]], grad_fn=<AddmmBackward>)\n",
      "after mmc: tensor([[0.1935],\n",
      "        [0.3961],\n",
      "        [0.5173]], grad_fn=<MmBackward>)\n",
      "\n",
      "layers: ['conv1.weight', 'conv2.weight', 'conv3.weight', 'conv4.weight', 'fc1.weight', 'fc2.weight']\n",
      "max: [tensor(8.8119), tensor(22.9399), tensor(35.9523), tensor(24.6588), tensor(2.1775), tensor(49.9547)]\n",
      "mean: [tensor(2.5649), tensor(1.2505), tensor(2.1678), tensor(3.5421), tensor(0.1861), tensor(3.4252)]\n",
      "\n",
      "\n",
      "before mmc: tensor([[0.1485, 0.4069, 0.6074]], grad_fn=<AddmmBackward>)\n",
      "after mmc: tensor([[0.2299],\n",
      "        [0.4589],\n",
      "        [0.6074]], grad_fn=<MmBackward>)\n",
      "\n",
      "layers: ['conv1.weight', 'conv2.weight', 'conv3.weight', 'conv4.weight', 'fc1.weight', 'fc2.weight']\n",
      "max: [tensor(9.6258), tensor(23.9603), tensor(39.7646), tensor(25.7717), tensor(2.0875), tensor(48.9277)]\n",
      "mean: [tensor(2.9433), tensor(1.3530), tensor(2.2984), tensor(3.9164), tensor(0.1860), tensor(3.4481)]\n",
      "\n",
      "\n",
      "before mmc: tensor([[0.1817, 0.4614, 0.7145]], grad_fn=<AddmmBackward>)\n",
      "after mmc: tensor([[0.2740],\n",
      "        [0.5328],\n",
      "        [0.7145]], grad_fn=<MmBackward>)\n",
      "\n",
      "layers: ['conv1.weight', 'conv2.weight', 'conv3.weight', 'conv4.weight', 'fc1.weight', 'fc2.weight']\n",
      "max: [tensor(11.3302), tensor(26.5171), tensor(48.0833), tensor(31.0141), tensor(2.2683), tensor(54.3500)]\n",
      "mean: [tensor(3.8721), tensor(1.7095), tensor(2.6943), tensor(4.9220), tensor(0.1982), tensor(3.9198)]\n",
      "\n",
      "\n",
      "before mmc: tensor([[0.2217, 0.5287, 0.8456]], grad_fn=<AddmmBackward>)\n",
      "after mmc: tensor([[0.3274],\n",
      "        [0.6240],\n",
      "        [0.8456]], grad_fn=<MmBackward>)\n",
      "\n",
      "layers: ['conv1.weight', 'conv2.weight', 'conv3.weight', 'conv4.weight', 'fc1.weight', 'fc2.weight']\n",
      "max: [tensor(10.6002), tensor(24.1610), tensor(44.0448), tensor(28.0482), tensor(1.8580), tensor(45.4177)]\n",
      "mean: [tensor(3.6044), tensor(1.5840), tensor(2.5445), tensor(4.6109), tensor(0.1637), tensor(3.3609)]\n",
      "\n",
      "\n",
      "before mmc: tensor([[0.2710, 0.6098, 1.0020]], grad_fn=<AddmmBackward>)\n",
      "after mmc: tensor([[0.3930],\n",
      "        [0.7310],\n",
      "        [1.0020]], grad_fn=<MmBackward>)\n",
      "\n",
      "layers: ['conv1.weight', 'conv2.weight', 'conv3.weight', 'conv4.weight', 'fc1.weight', 'fc2.weight']\n",
      "max: [tensor(15.2824), tensor(34.1812), tensor(62.0994), tensor(39.0169), tensor(2.3975), tensor(59.6023)]\n",
      "mean: [tensor(5.1235), tensor(2.2523), tensor(3.7251), tensor(6.7163), tensor(0.2184), tensor(4.5129)]\n",
      "\n",
      "\n",
      "before mmc: tensor([[0.3313, 0.7102, 1.1929]], grad_fn=<AddmmBackward>)\n",
      "after mmc: tensor([[0.4733],\n",
      "        [0.8616],\n",
      "        [1.1929]], grad_fn=<MmBackward>)\n",
      "\n",
      "layers: ['conv1.weight', 'conv2.weight', 'conv3.weight', 'conv4.weight', 'fc1.weight', 'fc2.weight']\n",
      "max: [tensor(8.0634), tensor(17.6627), tensor(31.9943), tensor(20.2038), tensor(1.1177), tensor(28.3315)]\n",
      "mean: [tensor(2.7393), tensor(1.1796), tensor(1.9892), tensor(3.5044), tensor(0.0999), tensor(2.2010)]\n",
      "\n",
      "\n",
      "before mmc: tensor([[0.4058, 0.8321, 1.4216]], grad_fn=<AddmmBackward>)\n",
      "after mmc: tensor([[0.5723],\n",
      "        [1.0158],\n",
      "        [1.4216]], grad_fn=<MmBackward>)\n",
      "\n",
      "layers: ['conv1.weight', 'conv2.weight', 'conv3.weight', 'conv4.weight', 'fc1.weight', 'fc2.weight']\n",
      "max: [tensor(31.0731), tensor(65.2983), tensor(117.8352), tensor(74.8855), tensor(3.8543), tensor(98.6045)]\n",
      "mean: [tensor(10.5244), tensor(4.4971), tensor(7.6320), tensor(13.3556), tensor(0.3446), tensor(7.7993)]\n",
      "\n",
      "\n",
      "before mmc: tensor([[0.4949, 0.9746, 1.6879]], grad_fn=<AddmmBackward>)\n",
      "after mmc: tensor([[0.6898],\n",
      "        [1.1930],\n",
      "        [1.6879]], grad_fn=<MmBackward>)\n",
      "\n",
      "layers: ['conv1.weight', 'conv2.weight', 'conv3.weight', 'conv4.weight', 'fc1.weight', 'fc2.weight']\n",
      "max: [tensor(21.2653), tensor(42.2836), tensor(77.0570), tensor(48.9550), tensor(2.4005), tensor(61.4581)]\n",
      "mean: [tensor(7.0881), tensor(3.0750), tensor(5.0950), tensor(8.9920), tensor(0.2128), tensor(4.9622)]\n",
      "\n",
      "\n",
      "before mmc: tensor([[0.6060, 1.1530, 2.0163]], grad_fn=<AddmmBackward>)\n",
      "after mmc: tensor([[0.8366],\n",
      "        [1.4103],\n",
      "        [2.0163]], grad_fn=<MmBackward>)\n",
      "\n",
      "layers: ['conv1.weight', 'conv2.weight', 'conv3.weight', 'conv4.weight', 'fc1.weight', 'fc2.weight']\n",
      "max: [tensor(20.2953), tensor(40.0212), tensor(72.4551), tensor(46.4638), tensor(2.1650), tensor(55.5211)]\n",
      "mean: [tensor(6.9010), tensor(2.9009), tensor(4.9820), tensor(8.7680), tensor(0.1904), tensor(4.5796)]\n",
      "\n",
      "\n",
      "before mmc: tensor([[0.7425, 1.3681, 2.4096]], grad_fn=<AddmmBackward>)\n",
      "after mmc: tensor([[1.0161],\n",
      "        [1.6672],\n",
      "        [2.4096]], grad_fn=<MmBackward>)\n",
      "\n",
      "layers: ['conv1.weight', 'conv2.weight', 'conv3.weight', 'conv4.weight', 'fc1.weight', 'fc2.weight']\n",
      "max: [tensor(61.9341), tensor(121.3271), tensor(219.4976), tensor(144.4422), tensor(6.3663), tensor(163.7862)]\n",
      "mean: [tensor(22.4235), tensor(9.1248), tensor(15.6938), tensor(27.5902), tensor(0.5720), tensor(13.6421)]\n",
      "\n",
      "\n",
      "before mmc: tensor([[0.9088, 1.6275, 2.8765]], grad_fn=<AddmmBackward>)\n",
      "after mmc: tensor([[1.2343],\n",
      "        [1.9677],\n",
      "        [2.8765]], grad_fn=<MmBackward>)\n",
      "\n",
      "layers: ['conv1.weight', 'conv2.weight', 'conv3.weight', 'conv4.weight', 'fc1.weight', 'fc2.weight']\n",
      "max: [tensor(59.2711), tensor(113.8247), tensor(204.8588), tensor(134.9391), tensor(5.7494), tensor(149.9407)]\n",
      "mean: [tensor(21.8068), tensor(8.6632), tensor(15.3013), tensor(26.6682), tensor(0.5005), tensor(12.6508)]\n",
      "\n",
      "\n",
      "before mmc: tensor([[1.1141, 1.9441, 3.4432]], grad_fn=<AddmmBackward>)\n",
      "after mmc: tensor([[1.5029],\n",
      "        [2.3291],\n",
      "        [3.4432]], grad_fn=<MmBackward>)\n",
      "\n",
      "layers: ['conv1.weight', 'conv2.weight', 'conv3.weight', 'conv4.weight', 'fc1.weight', 'fc2.weight']\n",
      "max: [tensor(6.7100), tensor(12.6677), tensor(22.6599), tensor(15.0916), tensor(0.5988), tensor(15.9996)]\n",
      "mean: [tensor(2.4938), tensor(0.9815), tensor(1.7590), tensor(3.0584), tensor(0.0536), tensor(1.4488)]\n",
      "\n",
      "\n",
      "before mmc: tensor([[1.3538, 2.3045, 4.0790]], grad_fn=<AddmmBackward>)\n",
      "after mmc: tensor([[1.8147],\n",
      "        [2.7252],\n",
      "        [4.0790]], grad_fn=<MmBackward>)\n",
      "\n",
      "layers: ['conv1.weight', 'conv2.weight', 'conv3.weight', 'conv4.weight', 'fc1.weight', 'fc2.weight']\n",
      "max: [tensor(116.5388), tensor(215.5205), tensor(383.6169), tensor(259.8836), tensor(10.2640), tensor(276.9384)]\n",
      "mean: [tensor(43.8532), tensor(17.1599), tensor(31.0499), tensor(53.4564), tensor(0.9174), tensor(23.7201)]\n",
      "\n",
      "\n",
      "before mmc: tensor([[1.6393, 2.7254, 4.8183]], grad_fn=<AddmmBackward>)\n",
      "after mmc: tensor([[2.1844],\n",
      "        [3.1790],\n",
      "        [4.8183]], grad_fn=<MmBackward>)\n",
      "\n",
      "layers: ['conv1.weight', 'conv2.weight', 'conv3.weight', 'conv4.weight', 'fc1.weight', 'fc2.weight']\n",
      "max: [tensor(7.7908), tensor(14.6071), tensor(25.8133), tensor(17.6273), tensor(0.6504), tensor(17.9532)]\n",
      "mean: [tensor(3.0543), tensor(1.2087), tensor(2.1691), tensor(3.7282), tensor(0.0609), tensor(1.7011)]\n",
      "\n",
      "\n",
      "before mmc: tensor([[1.9657, 3.1932, 5.6292]], grad_fn=<AddmmBackward>)\n",
      "after mmc: tensor([[2.6043],\n",
      "        [3.6635],\n",
      "        [5.6292]], grad_fn=<MmBackward>)\n",
      "\n",
      "layers: ['conv1.weight', 'conv2.weight', 'conv3.weight', 'conv4.weight', 'fc1.weight', 'fc2.weight']\n",
      "max: [tensor(167.1950), tensor(308.2905), tensor(546.8941), tensor(375.6697), tensor(14.1754), tensor(394.0768)]\n",
      "mean: [tensor(66.6940), tensor(26.1481), tensor(47.3905), tensor(81.0151), tensor(1.2409), tensor(34.2794)]\n",
      "\n",
      "\n",
      "before mmc: tensor([[2.3734, 3.7734, 6.6269]], grad_fn=<AddmmBackward>)\n",
      "after mmc: tensor([[3.1280],\n",
      "        [4.2536],\n",
      "        [6.6269]], grad_fn=<MmBackward>)\n",
      "\n",
      "layers: ['conv1.weight', 'conv2.weight', 'conv3.weight', 'conv4.weight', 'fc1.weight', 'fc2.weight']\n",
      "max: [tensor(78.7129), tensor(137.7511), tensor(242.0664), tensor(169.3142), tensor(6.1776), tensor(175.1968)]\n",
      "mean: [tensor(30.7784), tensor(11.6793), tensor(21.7988), tensor(37.2944), tensor(0.5469), tensor(15.5021)]\n",
      "\n",
      "\n",
      "before mmc: tensor([[2.8724, 4.4789, 7.8311]], grad_fn=<AddmmBackward>)\n",
      "after mmc: tensor([[3.7682],\n",
      "        [4.9587],\n",
      "        [7.8311]], grad_fn=<MmBackward>)\n",
      "\n",
      "layers: ['conv1.weight', 'conv2.weight', 'conv3.weight', 'conv4.weight', 'fc1.weight', 'fc2.weight']\n",
      "max: [tensor(110.2578), tensor(190.4216), tensor(335.4521), tensor(236.4369), tensor(8.4251), tensor(243.3226)]\n",
      "mean: [tensor(43.9545), tensor(16.6983), tensor(31.2894), tensor(52.7166), tensor(0.7518), tensor(21.6537)]\n",
      "\n",
      "\n",
      "before mmc: tensor([[3.4924, 5.3458, 9.2994]], grad_fn=<AddmmBackward>)\n",
      "after mmc: tensor([[4.5615],\n",
      "        [5.8070],\n",
      "        [9.2994]], grad_fn=<MmBackward>)\n",
      "\n",
      "layers: ['conv1.weight', 'conv2.weight', 'conv3.weight', 'conv4.weight', 'fc1.weight', 'fc2.weight']\n",
      "max: [tensor(54.6999), tensor(92.6667), tensor(162.4057), tensor(116.2086), tensor(4.0245), tensor(118.0644)]\n",
      "mean: [tensor(22.3600), tensor(8.3373), tensor(15.7215), tensor(26.4575), tensor(0.3666), tensor(10.8336)]\n",
      "\n",
      "\n",
      "before mmc: tensor([[ 4.2454,  6.3859, 11.0423]], grad_fn=<AddmmBackward>)\n",
      "after mmc: tensor([[ 5.5226],\n",
      "        [ 6.7969],\n",
      "        [11.0423]], grad_fn=<MmBackward>)\n",
      "\n",
      "layers: ['conv1.weight', 'conv2.weight', 'conv3.weight', 'conv4.weight', 'fc1.weight', 'fc2.weight']\n",
      "max: [tensor(227.9838), tensor(381.8133), tensor(658.4229), tensor(480.9910), tensor(16.5876), tensor(494.4563)]\n",
      "mean: [tensor(95.2101), tensor(35.2896), tensor(67.3859), tensor(111.9283), tensor(1.5657), tensor(44.5814)]\n",
      "\n",
      "\n",
      "before mmc: tensor([[ 5.1785,  7.6804, 13.1825]], grad_fn=<AddmmBackward>)\n",
      "after mmc: tensor([[ 6.7146],\n",
      "        [ 8.0040],\n",
      "        [13.1825]], grad_fn=<MmBackward>)\n",
      "\n",
      "layers: ['conv1.weight', 'conv2.weight', 'conv3.weight', 'conv4.weight', 'fc1.weight', 'fc2.weight']\n",
      "max: [tensor(162.4936), tensor(268.3035), tensor(461.0378), tensor(343.0009), tensor(11.5676), tensor(350.8418)]\n",
      "mean: [tensor(69.2359), tensor(25.4078), tensor(49.1276), tensor(81.4476), tensor(1.1134), tensor(32.1891)]\n",
      "\n",
      "\n",
      "before mmc: tensor([[ 6.3437,  9.2928, 15.8209]], grad_fn=<AddmmBackward>)\n",
      "after mmc: tensor([[ 8.2022],\n",
      "        [ 9.4773],\n",
      "        [15.8209]], grad_fn=<MmBackward>)\n",
      "\n",
      "layers: ['conv1.weight', 'conv2.weight', 'conv3.weight', 'conv4.weight', 'fc1.weight', 'fc2.weight']\n",
      "max: [tensor(144.4669), tensor(234.7938), tensor(399.7072), tensor(303.3774), tensor(10.0544), tensor(310.3863)]\n",
      "mean: [tensor(66.7440), tensor(22.8233), tensor(44.6171), tensor(73.7160), tensor(0.9872), tensor(28.9615)]\n",
      "\n",
      "\n",
      "before mmc: tensor([[ 7.8072, 11.3086, 19.0844]], grad_fn=<AddmmBackward>)\n",
      "after mmc: tensor([[10.0689],\n",
      "        [11.2772],\n",
      "        [19.0844]], grad_fn=<MmBackward>)\n",
      "\n",
      "layers: ['conv1.weight', 'conv2.weight', 'conv3.weight', 'conv4.weight', 'fc1.weight', 'fc2.weight']\n",
      "max: [tensor(429.6522), tensor(681.8099), tensor(1152.1909), tensor(892.7046), tensor(29.3865), tensor(926.6409)]\n",
      "mean: [tensor(200.8534), tensor(68.9037), tensor(134.7961), tensor(222.2545), tensor(2.9217), tensor(85.9801)]\n",
      "\n",
      "\n",
      "before mmc: tensor([[ 9.5320, 13.6467, 22.8382]], grad_fn=<AddmmBackward>)\n",
      "after mmc: tensor([[12.2614],\n",
      "        [13.3062],\n",
      "        [22.8382]], grad_fn=<MmBackward>)\n",
      "\n",
      "layers: ['conv1.weight', 'conv2.weight', 'conv3.weight', 'conv4.weight', 'fc1.weight', 'fc2.weight']\n",
      "max: [tensor(13.0571), tensor(20.2261), tensor(33.9110), tensor(26.9358), tensor(0.8461), tensor(22.1036)]\n",
      "mean: [tensor(6.2124), tensor(2.1118), tensor(4.1378), tensor(6.8026), tensor(0.0882), tensor(3.1082)]\n",
      "\n",
      "\n",
      "before mmc: tensor([[11.4909, 16.2094, 26.9280]], grad_fn=<AddmmBackward>)\n",
      "after mmc: tensor([[14.7328],\n",
      "        [15.4370],\n",
      "        [26.9280]], grad_fn=<MmBackward>)\n",
      "\n",
      "layers: ['conv1.weight', 'conv2.weight', 'conv3.weight', 'conv4.weight', 'fc1.weight', 'fc2.weight']\n",
      "max: [tensor(543.3599), tensor(827.7318), tensor(1384.4138), tensor(1111.7744), tensor(35.7446), tensor(1169.5304)]\n",
      "mean: [tensor(261.1876), tensor(89.0872), tensor(175.4269), tensor(287.8045), tensor(3.7231), tensor(110.3871)]\n",
      "\n",
      "\n",
      "before mmc: tensor([[13.8916, 19.3325, 31.8804]], grad_fn=<AddmmBackward>)\n",
      "after mmc: tensor([[17.7581],\n",
      "        [17.9888],\n",
      "        [31.8804]], grad_fn=<MmBackward>)\n",
      "\n",
      "layers: ['conv1.weight', 'conv2.weight', 'conv3.weight', 'conv4.weight', 'fc1.weight', 'fc2.weight']\n",
      "max: [tensor(39.0460), tensor(58.1839), tensor(96.5936), tensor(79.1382), tensor(2.4791), tensor(77.3861)]\n",
      "mean: [tensor(18.9577), tensor(6.4450), tensor(12.7898), tensor(20.8270), tensor(0.2649), tensor(8.3801)]\n",
      "\n",
      "\n",
      "before mmc: tensor([[16.5757, 22.7838, 37.2884]], grad_fn=<AddmmBackward>)\n",
      "after mmc: tensor([[21.1325],\n",
      "        [20.7127],\n",
      "        [37.2884]], grad_fn=<MmBackward>)\n",
      "\n",
      "layers: ['conv1.weight', 'conv2.weight', 'conv3.weight', 'conv4.weight', 'fc1.weight', 'fc2.weight']\n",
      "max: [tensor(253.1373), tensor(370.4709), tensor(612.2238), tensor(508.2288), tensor(16.0483), tensor(542.7207)]\n",
      "mean: [tensor(124.3478), tensor(42.1380), tensor(83.8315), tensor(136.4458), tensor(1.7213), tensor(52.9466)]\n",
      "\n",
      "\n",
      "before mmc: tensor([[19.6600, 26.9663, 43.7915]], grad_fn=<AddmmBackward>)\n",
      "after mmc: tensor([[25.0532],\n",
      "        [24.1315],\n",
      "        [43.7915]], grad_fn=<MmBackward>)\n",
      "\n",
      "layers: ['conv1.weight', 'conv2.weight', 'conv3.weight', 'conv4.weight', 'fc1.weight', 'fc2.weight']\n",
      "max: [tensor(613.5768), tensor(879.0515), tensor(1448.7776), tensor(1222.5702), tensor(38.4510), tensor(1332.1116)]\n",
      "mean: [tensor(316.3899), tensor(103.1201), tensor(205.6506), tensor(334.3619), tensor(4.1742), tensor(129.3788)]\n",
      "\n",
      "\n",
      "before mmc: tensor([[23.1107, 32.1611, 51.8358]], grad_fn=<AddmmBackward>)\n",
      "after mmc: tensor([[29.5429],\n",
      "        [28.7251],\n",
      "        [51.8358]], grad_fn=<MmBackward>)\n",
      "\n",
      "layers: ['conv1.weight', 'conv2.weight', 'conv3.weight', 'conv4.weight', 'fc1.weight', 'fc2.weight']\n",
      "max: [tensor(104.5897), tensor(146.6054), tensor(240.7420), tensor(206.8445), tensor(6.6411), tensor(240.1577)]\n",
      "mean: [tensor(54.6601), tensor(17.7518), tensor(35.4260), tensor(57.5934), tensor(0.7121), tensor(21.8736)]\n",
      "\n",
      "\n",
      "before mmc: tensor([[26.1991, 37.2954, 59.6297]], grad_fn=<AddmmBackward>)\n",
      "after mmc: tensor([[33.6582],\n",
      "        [33.4306],\n",
      "        [59.6297]], grad_fn=<MmBackward>)\n",
      "\n",
      "layers: ['conv1.weight', 'conv2.weight', 'conv3.weight', 'conv4.weight', 'fc1.weight', 'fc2.weight']\n",
      "max: [tensor(309.1697), tensor(425.3563), tensor(699.3885), tensor(609.6247), tensor(19.0769), tensor(702.1510)]\n",
      "mean: [tensor(162.9206), tensor(52.9631), tensor(105.6880), tensor(171.8468), tensor(2.1070), tensor(64.9623)]\n",
      "\n",
      "\n",
      "before mmc: tensor([[28.4079, 41.3052, 65.4750]], grad_fn=<AddmmBackward>)\n",
      "after mmc: tensor([[36.6689],\n",
      "        [37.0671],\n",
      "        [65.4750]], grad_fn=<MmBackward>)\n",
      "\n",
      "layers: ['conv1.weight', 'conv2.weight', 'conv3.weight', 'conv4.weight', 'fc1.weight', 'fc2.weight']\n",
      "max: [tensor(3.9099), tensor(5.3503), tensor(8.7359), tensor(7.6005), tensor(1.1561), tensor(38.4090)]\n",
      "mean: [tensor(2.0657), tensor(0.6742), tensor(1.3483), tensor(2.2153), tensor(0.0757), tensor(7.0326)]\n",
      "\n",
      "\n",
      "before mmc: tensor([[30.6973, 45.3395, 71.1785]], grad_fn=<AddmmBackward>)\n",
      "after mmc: tensor([[39.7652],\n",
      "        [40.4813],\n",
      "        [71.1785]], grad_fn=<MmBackward>)\n",
      "\n",
      "layers: ['conv1.weight', 'conv2.weight', 'conv3.weight', 'conv4.weight', 'fc1.weight', 'fc2.weight']\n",
      "max: [tensor(620.4412), tensor(836.3669), tensor(1379.8619), tensor(1221.6674), tensor(37.8073), tensor(1419.6884)]\n",
      "mean: [tensor(330.0876), tensor(107.2893), tensor(213.8107), tensor(348.7399), tensor(4.2289), tensor(134.2086)]\n",
      "\n",
      "\n",
      "before mmc: tensor([[31.5513, 46.6299, 72.5392]], grad_fn=<AddmmBackward>)\n",
      "after mmc: tensor([[40.8773],\n",
      "        [40.9880],\n",
      "        [72.5392]], grad_fn=<MmBackward>)\n",
      "\n",
      "layers: ['conv1.weight', 'conv2.weight', 'conv3.weight', 'conv4.weight', 'fc1.weight', 'fc2.weight']\n",
      "max: [tensor(904.6959), tensor(1222.1024), tensor(2018.9796), tensor(1790.4843), tensor(53.9914), tensor(1995.4056)]\n",
      "mean: [tensor(482.1522), tensor(156.5221), tensor(311.6177), tensor(509.3272), tensor(6.1538), tensor(198.0068)]\n",
      "\n",
      "\n",
      "before mmc: tensor([[33.8847, 50.3308, 77.5901]], grad_fn=<AddmmBackward>)\n",
      "after mmc: tensor([[43.9509],\n",
      "        [43.7054],\n",
      "        [77.5901]], grad_fn=<MmBackward>)\n",
      "\n",
      "layers: ['conv1.weight', 'conv2.weight', 'conv3.weight', 'conv4.weight', 'fc1.weight', 'fc2.weight']\n",
      "max: [tensor(303.1289), tensor(405.8872), tensor(671.6894), tensor(599.0251), tensor(17.9275), tensor(649.0021)]\n",
      "mean: [tensor(161.9579), tensor(52.5626), tensor(104.6872), tensor(171.2821), tensor(2.0594), tensor(68.3513)]\n",
      "\n",
      "\n",
      "before mmc: tensor([[36.5900, 54.9361, 83.8689]], grad_fn=<AddmmBackward>)\n",
      "after mmc: tensor([[47.5772],\n",
      "        [47.2789],\n",
      "        [83.8689]], grad_fn=<MmBackward>)\n",
      "\n",
      "layers: ['conv1.weight', 'conv2.weight', 'conv3.weight', 'conv4.weight', 'fc1.weight', 'fc2.weight']\n",
      "max: [tensor(880.7394), tensor(1169.3032), tensor(1937.5845), tensor(1738.8131), tensor(51.9981), tensor(1954.5396)]\n",
      "mean: [tensor(472.7965), tensor(153.4883), tensor(305.9330), tensor(501.1339), tensor(6.0045), tensor(196.5363)]\n",
      "\n",
      "\n",
      "before mmc: tensor([[40.2837, 61.5692, 93.1264]], grad_fn=<AddmmBackward>)\n",
      "after mmc: tensor([[52.5975],\n",
      "        [52.8428],\n",
      "        [93.1264]], grad_fn=<MmBackward>)\n",
      "\n",
      "layers: ['conv1.weight', 'conv2.weight', 'conv3.weight', 'conv4.weight', 'fc1.weight', 'fc2.weight']\n",
      "max: [tensor(837.3086), tensor(1096.8027), tensor(1816.0369), tensor(1647.9913), tensor(48.8072), tensor(1853.1686)]\n",
      "mean: [tensor(453.2864), tensor(146.6112), tensor(292.4561), tensor(479.4044), tensor(5.7273), tensor(188.6479)]\n",
      "\n",
      "\n",
      "before mmc: tensor([[ 45.2271,  70.2329, 105.2781]], grad_fn=<AddmmBackward>)\n",
      "after mmc: tensor([[ 59.2736],\n",
      "        [ 60.0511],\n",
      "        [105.2781]], grad_fn=<MmBackward>)\n",
      "\n",
      "layers: ['conv1.weight', 'conv2.weight', 'conv3.weight', 'conv4.weight', 'fc1.weight', 'fc2.weight']\n",
      "max: [tensor(786.7624), tensor(1014.1436), tensor(1674.6268), tensor(1539.3086), tensor(46.8865), tensor(1871.5516)]\n",
      "mean: [tensor(430.8889), tensor(138.4857), tensor(276.3050), tensor(453.7170), tensor(5.3898), tensor(175.9943)]\n",
      "\n",
      "\n",
      "before mmc: tensor([[ 48.8091,  76.0090, 112.7488]], grad_fn=<AddmmBackward>)\n",
      "after mmc: tensor([[ 64.0109],\n",
      "        [ 63.9397],\n",
      "        [112.7488]], grad_fn=<MmBackward>)\n",
      "\n",
      "layers: ['conv1.weight', 'conv2.weight', 'conv3.weight', 'conv4.weight', 'fc1.weight', 'fc2.weight']\n",
      "max: [tensor(949.6858), tensor(1214.4584), tensor(2004.5863), tensor(1855.8650), tensor(56.0282), tensor(2254.9822)]\n",
      "mean: [tensor(522.8763), tensor(167.5954), tensor(334.5994), tensor(550.1695), tensor(6.5126), tensor(211.6852)]\n",
      "\n",
      "\n",
      "before mmc: tensor([[ 50.2754,  78.3607, 114.9553]], grad_fn=<AddmmBackward>)\n",
      "after mmc: tensor([[ 65.9476],\n",
      "        [ 64.6799],\n",
      "        [114.9553]], grad_fn=<MmBackward>)\n",
      "\n",
      "layers: ['conv1.weight', 'conv2.weight', 'conv3.weight', 'conv4.weight', 'fc1.weight', 'fc2.weight']\n",
      "max: [tensor(30.6162), tensor(39.0885), tensor(64.6330), tensor(60.5491), tensor(2.5634), tensor(114.4963)]\n",
      "mean: [tensor(16.8529), tensor(5.4032), tensor(10.7991), tensor(17.7478), tensor(0.2411), tensor(13.8847)]\n",
      "\n",
      "\n",
      "before mmc: tensor([[ 50.8546,  80.7617, 117.0421]], grad_fn=<AddmmBackward>)\n",
      "after mmc: tensor([[ 67.0069],\n",
      "        [ 66.1875],\n",
      "        [117.0421]], grad_fn=<MmBackward>)\n",
      "\n",
      "layers: ['conv1.weight', 'conv2.weight', 'conv3.weight', 'conv4.weight', 'fc1.weight', 'fc2.weight']\n",
      "max: [tensor(840.8011), tensor(1071.2744), tensor(1769.3600), tensor(1644.7423), tensor(49.4247), tensor(2009.8409)]\n",
      "mean: [tensor(463.5472), tensor(148.1224), tensor(296.3065), tensor(488.4796), tensor(5.7663), tensor(188.8047)]\n",
      "\n",
      "\n",
      "before mmc: tensor([[ 49.5718,  80.5007, 115.2211]], grad_fn=<AddmmBackward>)\n",
      "after mmc: tensor([[ 65.6719],\n",
      "        [ 65.6493],\n",
      "        [115.2211]], grad_fn=<MmBackward>)\n",
      "\n",
      "layers: ['conv1.weight', 'conv2.weight', 'conv3.weight', 'conv4.weight', 'fc1.weight', 'fc2.weight']\n",
      "max: [tensor(25.1890), tensor(32.1390), tensor(53.1067), tensor(50.2674), tensor(2.6973), tensor(116.2792)]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-f4d1731a847e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m )\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_dl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-4d5f9c750516>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(net, optimizer, train_dl, test_dl, epochs)\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m             \u001b[0mgrad_flow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-10da17ee1e39>\u001b[0m in \u001b[0;36mgrad_flow\u001b[1;34m(named_parameters)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'layers: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'max: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'mean: {}\\n\\n'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mave_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Miniconda3\\envs\\dl\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36m__repr__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;31m# characters to replace unicode characters with.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tensor_str\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'encoding'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\dl\\lib\\site-packages\\torch\\_tensor_str.py\u001b[0m in \u001b[0;36m_str\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    275\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhas_default_dtype\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m                 \u001b[0msuffixes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dtype='\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 277\u001b[1;33m             \u001b[0mtensor_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_tensor_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayout\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrided\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\dl\\lib\\site-packages\\torch\\_tensor_str.py\u001b[0m in \u001b[0;36m_tensor_str\u001b[1;34m(self, indent)\u001b[0m\n\u001b[0;32m    193\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m         \u001b[0mself\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 195\u001b[1;33m     \u001b[0mformatter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Formatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_summarized_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0msummarize\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_tensor_str_with_formatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\dl\\lib\\site-packages\\torch\\_tensor_str.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m             \u001b[0mnonzero_finite_vals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmasked_select\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_view\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_view\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[0mtensor_view\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mne\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mnonzero_finite_vals\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "net, optimizer = get_model(num_channel=2)\n",
    "\n",
    "train_dl, test_dl = get_data(\n",
    "    height=100, \n",
    "    width=100,\n",
    "    num_channel=2,\n",
    "    path='./data/data_simple_movement_1/',\n",
    "    size=8,\n",
    "    bs=1\n",
    ")\n",
    "\n",
    "fit(net, optimizer, train_dl, test_dl, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.04966],\n",
       "       [ 0.0709 ],\n",
       "       [ 0.0237 ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[-0.0472], [-0.0123],  [0.0237]])\n",
    "b = np.array([[1, 0.2, 0], [-1, 0, 1], [0, 0, 1]])\n",
    "np.dot(b, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#         iteration = 0\n",
    "#         while iteration < self.num_iter:\n",
    "#             for i in range(x.shape[0]):\n",
    "#                 x[i] = torch.matmul(self.weights, x[i])\n",
    "#             iteration += 1\n",
    "        # x = torch.acos(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[1, 2, 3]])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [2],\n",
       "        [3]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.transpose(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
