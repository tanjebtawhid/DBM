{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchsummary import summary\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from simple_movement import SimpleMovement\n",
    "from data_generator import DataGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MMC(nn.Module):\n",
    "    \n",
    "    def __init__(self, beta=5, num_iter=1):\n",
    "        super(MMC, self).__init__()\n",
    "        self.df = 1. / beta\n",
    "        self.num_iter = num_iter\n",
    "        self.weights = nn.Parameter(\n",
    "            data= torch.tensor([[1, self.df, 0], [-1, 0, 1], [0, 0, 1]]),\n",
    "            requires_grad=False\n",
    "        ) # .unsqueeze(0).expand(9, 3, 3)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        # = torch.bmm(torch.pow(self.weights, self.num_iter), x.unsqueeze(2)).squeeze(2)\n",
    "        x = torch.matmul(self.weights, x.transpose(0, 1))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_channel):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=num_channel, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 8, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(8, 8, 3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(8, 8, 2)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(200, 128)\n",
    "        self.fc2 = nn.Linear(128, 3)\n",
    "        self.mmc = MMC()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = self.pool(F.relu(self.conv4(x)))\n",
    "        x = x.view(-1, 5*5*8)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        # print('before mmc: {}'.format(x))\n",
    "        x = self.mmc(x)\n",
    "        # print('after mmc: {}\\n'.format(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight torch.Size([16, 1, 3, 3])\n",
      "conv1.bias torch.Size([16])\n",
      "conv2.weight torch.Size([8, 16, 3, 3])\n",
      "conv2.bias torch.Size([8])\n",
      "conv3.weight torch.Size([8, 8, 3, 3])\n",
      "conv3.bias torch.Size([8])\n",
      "conv4.weight torch.Size([8, 8, 2, 2])\n",
      "conv4.bias torch.Size([8])\n",
      "fc1.weight torch.Size([128, 200])\n",
      "fc1.bias torch.Size([128])\n",
      "fc2.weight torch.Size([3, 128])\n",
      "fc2.bias torch.Size([3])\n",
      "mmc.weights torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "model = Encoder(1)\n",
    "for n, p in model.named_parameters():\n",
    "    print(n, p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary(model, (1, 100, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(num_channel):\n",
    "    \n",
    "    net = Encoder(num_channel=num_channel)\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "    \n",
    "    return net, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tensor(x):\n",
    "    return torch.from_numpy(x).float()\n",
    "\n",
    "def get_data(height, width, num_channel, path, size, bs):\n",
    "    \n",
    "    dgen = DataGen(height, width, num_channel)\n",
    "    x, y = dgen.get_data(path, True, size, True)\n",
    "    print('Data loaded...\\nx:{}\\ty:{}\\n'.format(x.shape, y.shape))\n",
    "    \n",
    "    x = x / 255.\n",
    "    x = x[:90]\n",
    "    y = y[:90]\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, shuffle=True, random_state=331)\n",
    "    x_train, x_test, y_train, y_test = map(to_tensor, (x_train, x_test, y_train, y_test))\n",
    "    \n",
    "    train_ds = TensorDataset(x_train, y_train)\n",
    "    train_dl = DataLoader(train_ds, batch_size=bs, shuffle=True)\n",
    "\n",
    "    test_ds = TensorDataset(x_test, y_test)\n",
    "    test_dl = DataLoader(test_ds, batch_size=bs)\n",
    "    \n",
    "    return train_dl, test_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_flow(named_parameters):\n",
    "    ave_grads = []\n",
    "    max_grads= []\n",
    "    layers = []\n",
    "    for n, p in named_parameters:\n",
    "        if(p.requires_grad) and (\"bias\" not in n):\n",
    "            layers.append(n)\n",
    "            ave_grads.append(p.grad.abs().mean())\n",
    "            max_grads.append(p.grad.abs().max())\n",
    "    print('layers: {}'.format(layers))\n",
    "    print('max: {}'.format(max_grads))\n",
    "    print('mean: {}\\n\\n'.format( ave_grads))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(net, optimizer, train_dl, test_dl, epochs=5):\n",
    "    \n",
    "    loss_function = nn.MSELoss()\n",
    "    for epoch in range(epochs):\n",
    "        net.train()\n",
    "        for x, y in train_dl:\n",
    "            pred = net(x)\n",
    "            loss = loss_function(pred, y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            # grad_flow(net.named_parameters())\n",
    "            optimizer.step()\n",
    "\n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "            test_loss = sum(loss_function(net(x), y) for x, y in test_dl)\n",
    "        print('epoch:{}, test_loss:{}'.format(epoch+1, test_loss/len(test_dl)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded...\n",
      "x:(96, 2, 100, 100)\ty:(96, 3)\n",
      "\n",
      "epoch:1, test_loss:0.38404539227485657\n",
      "epoch:2, test_loss:0.376641184091568\n",
      "epoch:3, test_loss:0.37441131472587585\n",
      "epoch:4, test_loss:0.3738389313220978\n",
      "epoch:5, test_loss:0.37179863452911377\n",
      "epoch:6, test_loss:0.3714102804660797\n",
      "epoch:7, test_loss:0.3766249716281891\n",
      "epoch:8, test_loss:0.37311312556266785\n",
      "epoch:9, test_loss:0.3736895024776459\n",
      "epoch:10, test_loss:0.37159740924835205\n"
     ]
    }
   ],
   "source": [
    "net, optimizer = get_model(num_channel=2)\n",
    "\n",
    "train_dl, test_dl = get_data(\n",
    "    height=100, \n",
    "    width=100,\n",
    "    num_channel=2,\n",
    "    path='./data/data_simple_movement_2/',\n",
    "    size=8,\n",
    "    bs=1\n",
    ")\n",
    "\n",
    "fit(net, optimizer, train_dl, test_dl, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.04966],\n",
       "       [ 0.0709 ],\n",
       "       [ 0.0237 ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[-0.0472], [-0.0123],  [0.0237]])\n",
    "b = np.array([[1, 0.2, 0], [-1, 0, 1], [0, 0, 1]])\n",
    "np.dot(b, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#         iteration = 0\n",
    "#         while iteration < self.num_iter:\n",
    "#             for i in range(x.shape[0]):\n",
    "#                 x[i] = torch.matmul(self.weights, x[i])\n",
    "#             iteration += 1\n",
    "        # x = torch.acos(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[1, 2, 3]])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [2],\n",
       "        [3]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.transpose(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
