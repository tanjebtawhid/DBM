{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Lambda, Reshape, Flatten, ZeroPadding2D, Layer\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from data_generator import DataGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = './data/data_simple_movement/cartesian/'\n",
    "HEIGHT = 100\n",
    "WIDTH = 100\n",
    "NUM_CHANNEL = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MMCLayer(Layer):\n",
    "    \n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        super(MMCLayer, self).__init__(**kwargs)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(name='kernel',\n",
    "                                     shape=(input_shape[1], self.output_dim),\n",
    "                                     initializer='uniform',\n",
    "                                     trainable=True)\n",
    "        super(MMCLayer, self).build(input_shape)\n",
    "        \n",
    "    def call(self, x):\n",
    "        df = 1 / 5\n",
    "        w = np.array([\n",
    "            [1, df, 0], [-1, 0, 1], [0, 0, 1]\n",
    "        ])\n",
    "        # Can not set mmc target \n",
    "        return K.dot(K.dot(x, self.kernel), K.constant(w))\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 100, 100, 2)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 100, 100, 16)      304       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 50, 50, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 50, 50, 8)         1160      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 25, 25, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 25, 25, 8)         584       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 13, 13, 8)         0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 1352)              0         \n",
      "_________________________________________________________________\n",
      "mmc_layer_1 (MMCLayer)       (None, 3)                 4056      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1352)              5408      \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 13, 13, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 8)         584       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 26, 26, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 26, 26, 8)         584       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 52, 52, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 50, 50, 16)        1168      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 100, 100, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 100, 100, 1)       145       \n",
      "=================================================================\n",
      "Total params: 13,993\n",
      "Trainable params: 13,993\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_img = Input(shape=(HEIGHT, WIDTH, NUM_CHANNEL))\n",
    "\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "x = Reshape((13*13*8,))(x)\n",
    "x = MMCLayer(3)(x)\n",
    "x = Dense(13*13*8, activation='relu')(x)\n",
    "x = Reshape((13, 13, 8))(x)\n",
    "\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 86 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "86/86 [==============================] - 5s 61ms/step - loss: 0.6531 - val_loss: 0.4885\n",
      "Epoch 2/100\n",
      "86/86 [==============================] - 3s 29ms/step - loss: 0.2849 - val_loss: 0.2472\n",
      "Epoch 3/100\n",
      "86/86 [==============================] - 3s 30ms/step - loss: 0.1928 - val_loss: 0.1523\n",
      "Epoch 4/100\n",
      "86/86 [==============================] - 3s 32ms/step - loss: 0.1505 - val_loss: 0.1317\n",
      "Epoch 5/100\n",
      "86/86 [==============================] - 3s 38ms/step - loss: 0.1294 - val_loss: 0.1224\n",
      "Epoch 6/100\n",
      "86/86 [==============================] - 3s 34ms/step - loss: 0.1169 - val_loss: 0.1120\n",
      "Epoch 7/100\n",
      "86/86 [==============================] - 3s 30ms/step - loss: 0.1075 - val_loss: 0.1028\n",
      "Epoch 8/100\n",
      "86/86 [==============================] - 3s 29ms/step - loss: 0.0994 - val_loss: 0.0950\n",
      "Epoch 9/100\n",
      "86/86 [==============================] - 3s 31ms/step - loss: 0.0921 - val_loss: 0.0877\n",
      "Epoch 10/100\n",
      "86/86 [==============================] - 3s 37ms/step - loss: 0.0844 - val_loss: 0.0798\n",
      "Epoch 11/100\n",
      "86/86 [==============================] - 3s 37ms/step - loss: 0.0765 - val_loss: 0.0720\n",
      "Epoch 12/100\n",
      "86/86 [==============================] - 3s 35ms/step - loss: 0.0690 - val_loss: 0.0650\n",
      "Epoch 13/100\n",
      "86/86 [==============================] - 3s 37ms/step - loss: 0.0625 - val_loss: 0.0594\n",
      "Epoch 14/100\n",
      "86/86 [==============================] - 3s 35ms/step - loss: 0.0572 - val_loss: 0.0544\n",
      "Epoch 15/100\n",
      "86/86 [==============================] - 3s 39ms/step - loss: 0.0522 - val_loss: 0.0491\n",
      "Epoch 16/100\n",
      "86/86 [==============================] - 3s 37ms/step - loss: 0.0465 - val_loss: 0.0425\n",
      "Epoch 17/100\n",
      "86/86 [==============================] - 3s 33ms/step - loss: 0.0392 - val_loss: 0.0346\n",
      "Epoch 18/100\n",
      "86/86 [==============================] - 3s 34ms/step - loss: 0.0318 - val_loss: 0.0287\n",
      "Epoch 19/100\n",
      "86/86 [==============================] - 3s 39ms/step - loss: 0.0270 - val_loss: 0.0253\n",
      "Epoch 20/100\n",
      "86/86 [==============================] - 3s 38ms/step - loss: 0.0249 - val_loss: 0.0242\n",
      "Epoch 21/100\n",
      "86/86 [==============================] - 3s 37ms/step - loss: 0.0238 - val_loss: 0.0235\n",
      "Epoch 22/100\n",
      "86/86 [==============================] - 3s 39ms/step - loss: 0.0233 - val_loss: 0.0229\n",
      "Epoch 23/100\n",
      "86/86 [==============================] - 3s 33ms/step - loss: 0.0228 - val_loss: 0.0225\n",
      "Epoch 24/100\n",
      "86/86 [==============================] - 3s 34ms/step - loss: 0.0225 - val_loss: 0.0222\n",
      "Epoch 25/100\n",
      "86/86 [==============================] - 3s 35ms/step - loss: 0.0223 - val_loss: 0.0219\n",
      "Epoch 26/100\n",
      "86/86 [==============================] - 3s 38ms/step - loss: 0.0220 - val_loss: 0.0218\n",
      "Epoch 27/100\n",
      "86/86 [==============================] - 3s 39ms/step - loss: 0.0219 - val_loss: 0.0217\n",
      "Epoch 28/100\n",
      "86/86 [==============================] - 3s 40ms/step - loss: 0.0218 - val_loss: 0.0215\n",
      "Epoch 29/100\n",
      "86/86 [==============================] - 3s 39ms/step - loss: 0.0217 - val_loss: 0.0215\n",
      "Epoch 30/100\n",
      "86/86 [==============================] - 4s 49ms/step - loss: 0.0217 - val_loss: 0.0214\n",
      "Epoch 31/100\n",
      "86/86 [==============================] - 4s 47ms/step - loss: 0.0216 - val_loss: 0.0214\n",
      "Epoch 32/100\n",
      "86/86 [==============================] - 4s 43ms/step - loss: 0.0215 - val_loss: 0.0213\n",
      "Epoch 33/100\n",
      "86/86 [==============================] - 3s 39ms/step - loss: 0.0215 - val_loss: 0.0212\n",
      "Epoch 34/100\n",
      "86/86 [==============================] - 3s 38ms/step - loss: 0.0214 - val_loss: 0.0212\n",
      "Epoch 35/100\n",
      "86/86 [==============================] - 3s 39ms/step - loss: 0.0213 - val_loss: 0.0212\n",
      "Epoch 36/100\n",
      "86/86 [==============================] - 3s 38ms/step - loss: 0.0213 - val_loss: 0.0211\n",
      "Epoch 37/100\n",
      "86/86 [==============================] - 3s 36ms/step - loss: 0.0212 - val_loss: 0.0211\n",
      "Epoch 38/100\n",
      "86/86 [==============================] - 3s 35ms/step - loss: 0.0212 - val_loss: 0.0212\n",
      "Epoch 39/100\n",
      "86/86 [==============================] - 3s 35ms/step - loss: 0.0212 - val_loss: 0.0211\n",
      "Epoch 40/100\n",
      "86/86 [==============================] - 3s 34ms/step - loss: 0.0212 - val_loss: 0.0210\n",
      "Epoch 41/100\n",
      "86/86 [==============================] - 3s 34ms/step - loss: 0.0212 - val_loss: 0.0210\n",
      "Epoch 42/100\n",
      "86/86 [==============================] - 3s 34ms/step - loss: 0.0212 - val_loss: 0.0210\n",
      "Epoch 43/100\n",
      "86/86 [==============================] - 3s 34ms/step - loss: 0.0212 - val_loss: 0.0210\n",
      "Epoch 44/100\n",
      "86/86 [==============================] - 3s 37ms/step - loss: 0.0212 - val_loss: 0.0210\n",
      "Epoch 45/100\n",
      "86/86 [==============================] - 3s 34ms/step - loss: 0.0211 - val_loss: 0.0211\n",
      "Epoch 46/100\n",
      "86/86 [==============================] - 3s 34ms/step - loss: 0.0211 - val_loss: 0.0209\n",
      "Epoch 47/100\n",
      "86/86 [==============================] - 3s 35ms/step - loss: 0.0211 - val_loss: 0.0210\n",
      "Epoch 48/100\n",
      "86/86 [==============================] - 3s 33ms/step - loss: 0.0210 - val_loss: 0.0209\n",
      "Epoch 49/100\n",
      "86/86 [==============================] - 3s 35ms/step - loss: 0.0210 - val_loss: 0.0209\n",
      "Epoch 50/100\n",
      "86/86 [==============================] - 3s 33ms/step - loss: 0.0211 - val_loss: 0.0210\n",
      "Epoch 51/100\n",
      "86/86 [==============================] - 3s 35ms/step - loss: 0.0211 - val_loss: 0.0209\n",
      "Epoch 52/100\n",
      "86/86 [==============================] - 3s 37ms/step - loss: 0.0210 - val_loss: 0.0208\n",
      "Epoch 53/100\n",
      "86/86 [==============================] - 3s 40ms/step - loss: 0.0210 - val_loss: 0.0209\n",
      "Epoch 54/100\n",
      "86/86 [==============================] - 3s 36ms/step - loss: 0.0210 - val_loss: 0.0209\n",
      "Epoch 55/100\n",
      "86/86 [==============================] - 3s 34ms/step - loss: 0.0210 - val_loss: 0.0209\n",
      "Epoch 56/100\n",
      "86/86 [==============================] - 3s 35ms/step - loss: 0.0209 - val_loss: 0.0209\n",
      "Epoch 57/100\n",
      "86/86 [==============================] - 3s 35ms/step - loss: 0.0210 - val_loss: 0.0209\n",
      "Epoch 58/100\n",
      "86/86 [==============================] - 3s 35ms/step - loss: 0.0209 - val_loss: 0.0208\n",
      "Epoch 59/100\n",
      "86/86 [==============================] - 3s 37ms/step - loss: 0.0209 - val_loss: 0.0209\n",
      "Epoch 60/100\n",
      "86/86 [==============================] - 3s 37ms/step - loss: 0.0209 - val_loss: 0.0208\n",
      "Epoch 61/100\n",
      "86/86 [==============================] - 3s 34ms/step - loss: 0.0209 - val_loss: 0.0209\n",
      "Epoch 62/100\n",
      "86/86 [==============================] - 3s 34ms/step - loss: 0.0209 - val_loss: 0.0208\n",
      "Epoch 63/100\n",
      "86/86 [==============================] - 3s 34ms/step - loss: 0.0209 - val_loss: 0.0208\n",
      "Epoch 64/100\n",
      "86/86 [==============================] - 3s 33ms/step - loss: 0.0209 - val_loss: 0.0207\n",
      "Epoch 65/100\n",
      "86/86 [==============================] - 3s 36ms/step - loss: 0.0209 - val_loss: 0.0208\n",
      "Epoch 66/100\n",
      "86/86 [==============================] - 3s 36ms/step - loss: 0.0209 - val_loss: 0.0208\n",
      "Epoch 67/100\n",
      "86/86 [==============================] - 3s 39ms/step - loss: 0.0209 - val_loss: 0.0207\n",
      "Epoch 68/100\n",
      "86/86 [==============================] - 4s 41ms/step - loss: 0.0209 - val_loss: 0.0208\n",
      "Epoch 69/100\n",
      "86/86 [==============================] - 3s 35ms/step - loss: 0.0209 - val_loss: 0.0207\n",
      "Epoch 70/100\n",
      "86/86 [==============================] - 3s 35ms/step - loss: 0.0208 - val_loss: 0.0208\n",
      "Epoch 71/100\n",
      "86/86 [==============================] - 3s 34ms/step - loss: 0.0209 - val_loss: 0.0207\n",
      "Epoch 72/100\n",
      "86/86 [==============================] - 3s 33ms/step - loss: 0.0208 - val_loss: 0.0208\n",
      "Epoch 73/100\n",
      "86/86 [==============================] - 3s 33ms/step - loss: 0.0209 - val_loss: 0.0207\n",
      "Epoch 74/100\n",
      "86/86 [==============================] - 3s 34ms/step - loss: 0.0208 - val_loss: 0.0208\n",
      "Epoch 75/100\n",
      "86/86 [==============================] - 3s 33ms/step - loss: 0.0209 - val_loss: 0.0207\n",
      "Epoch 76/100\n",
      "86/86 [==============================] - 3s 35ms/step - loss: 0.0209 - val_loss: 0.0206\n",
      "Epoch 77/100\n",
      "86/86 [==============================] - 3s 36ms/step - loss: 0.0208 - val_loss: 0.0208\n",
      "Epoch 78/100\n",
      "86/86 [==============================] - 3s 34ms/step - loss: 0.0209 - val_loss: 0.0207\n",
      "Epoch 79/100\n",
      "86/86 [==============================] - 3s 34ms/step - loss: 0.0209 - val_loss: 0.0207\n",
      "Epoch 80/100\n",
      "86/86 [==============================] - 3s 37ms/step - loss: 0.0208 - val_loss: 0.0206\n",
      "Epoch 81/100\n",
      "86/86 [==============================] - 3s 36ms/step - loss: 0.0208 - val_loss: 0.0207\n",
      "Epoch 82/100\n",
      "86/86 [==============================] - 3s 37ms/step - loss: 0.0208 - val_loss: 0.0208\n",
      "Epoch 83/100\n",
      "86/86 [==============================] - 3s 35ms/step - loss: 0.0208 - val_loss: 0.0206\n",
      "Epoch 84/100\n",
      "86/86 [==============================] - 3s 36ms/step - loss: 0.0208 - val_loss: 0.0207\n",
      "Epoch 85/100\n",
      "86/86 [==============================] - 3s 34ms/step - loss: 0.0208 - val_loss: 0.0207\n",
      "Epoch 86/100\n",
      "86/86 [==============================] - 3s 34ms/step - loss: 0.0208 - val_loss: 0.0206\n",
      "Epoch 87/100\n",
      "86/86 [==============================] - 3s 33ms/step - loss: 0.0208 - val_loss: 0.0206\n",
      "Epoch 88/100\n",
      "86/86 [==============================] - 3s 38ms/step - loss: 0.0208 - val_loss: 0.0207\n",
      "Epoch 89/100\n",
      "86/86 [==============================] - 3s 36ms/step - loss: 0.0208 - val_loss: 0.0206\n",
      "Epoch 90/100\n",
      "86/86 [==============================] - 3s 35ms/step - loss: 0.0208 - val_loss: 0.0207\n",
      "Epoch 91/100\n",
      "86/86 [==============================] - 3s 36ms/step - loss: 0.0208 - val_loss: 0.0207\n",
      "Epoch 92/100\n",
      "86/86 [==============================] - 4s 48ms/step - loss: 0.0208 - val_loss: 0.0207\n",
      "Epoch 93/100\n",
      "86/86 [==============================] - 4s 45ms/step - loss: 0.0208 - val_loss: 0.0207\n",
      "Epoch 94/100\n",
      "86/86 [==============================] - 3s 40ms/step - loss: 0.0208 - val_loss: 0.0206\n",
      "Epoch 95/100\n",
      "86/86 [==============================] - 4s 48ms/step - loss: 0.0208 - val_loss: 0.0207\n",
      "Epoch 96/100\n",
      "86/86 [==============================] - 4s 42ms/step - loss: 0.0208 - val_loss: 0.0206\n",
      "Epoch 97/100\n",
      "86/86 [==============================] - 3s 36ms/step - loss: 0.0208 - val_loss: 0.0207\n",
      "Epoch 98/100\n",
      "86/86 [==============================] - 3s 36ms/step - loss: 0.0208 - val_loss: 0.0207\n",
      "Epoch 99/100\n",
      "86/86 [==============================] - 4s 41ms/step - loss: 0.0208 - val_loss: 0.0205\n",
      "Epoch 100/100\n",
      "86/86 [==============================] - 4s 52ms/step - loss: 0.0208 - val_loss: 0.0208\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18bd6cb4b00>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dgen = DataGen(HEIGHT, WIDTH, NUM_CHANNEL)\n",
    "x, y = dgen.get_data(path=os.path.abspath(DATA_DIR),\n",
    "                     target_mmc_out=False,\n",
    "                     size=8,\n",
    "                     channel_first=False)\n",
    "\n",
    "x = x / 255.\n",
    "y = y / 255.\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, shuffle=True)\n",
    "\n",
    "autoencoder.fit(x_train, y_train,\n",
    "                epochs=100,\n",
    "                batch_size=10,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs = autoencoder.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 3\n",
    "\n",
    "fig, axes = plt.subplots(figsize=((10, 3)), nrows=1, ncols=NUM_CHANNEL+2)\n",
    "\n",
    "# display input images\n",
    "for i, ax in enumerate(axes.flat[:NUM_CHANNEL]):\n",
    "    ax.imshow(x_test[idx][:, :, i].reshape(HEIGHT, WIDTH), cmap='gray')\n",
    "    ax.axis('off'), ax.set_title('step ' + str(i+1))\n",
    "    \n",
    "# display prediction\n",
    "axes[NUM_CHANNEL].imshow(decoded_imgs[idx][:, :, 0].reshape(HEIGHT, WIDTH), cmap='gray')\n",
    "axes[NUM_CHANNEL].axis('off'), axes[NUM_CHANNEL].set_title('predicted')\n",
    "\n",
    "# display target\n",
    "axes[NUM_CHANNEL+1].imshow(y_test[idx][:, :, 0].reshape(HEIGHT, WIDTH), cmap='gray')\n",
    "axes[NUM_CHANNEL+1].axis('off'), axes[NUM_CHANNEL+1].set_title('target')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
