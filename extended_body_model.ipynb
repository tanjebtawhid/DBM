{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Lambda, Reshape, Flatten, ZeroPadding2D, Layer\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from data_generator import DataGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = './data/data_simple_movement/'\n",
    "HEIGHT = 100\n",
    "WIDTH = 100\n",
    "NUM_CHANNEL = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MMCLayer(Layer):\n",
    "    \n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        super(MMCLayer, self).__init__(**kwargs)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(name='kernel',\n",
    "                                     shape=(input_shape[1], self.output_dim),\n",
    "                                     initializer='uniform',\n",
    "                                     trainable=True)\n",
    "        super(MMCLayer, self).build(input_shape)\n",
    "        \n",
    "    def call(self, x):\n",
    "        df = 1 / 5\n",
    "        w = np.array([\n",
    "            [1, df, 0], [-1, 0, 1], [0, 0, 1]\n",
    "        ])\n",
    "        # Can not set mmc target \n",
    "        return K.dot(K.dot(x, self.kernel), K.constant(w))\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 100, 100, 2)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 100, 100, 16)      304       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 50, 50, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 50, 50, 8)         1160      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 25, 25, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 25, 25, 8)         584       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 13, 13, 8)         0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 1352)              0         \n",
      "_________________________________________________________________\n",
      "mmc_layer_1 (MMCLayer)       (None, 3)                 4056      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1352)              5408      \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 13, 13, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 8)         584       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 26, 26, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 26, 26, 8)         584       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 52, 52, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 50, 50, 16)        1168      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 100, 100, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 100, 100, 1)       145       \n",
      "=================================================================\n",
      "Total params: 13,993\n",
      "Trainable params: 13,993\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_img = Input(shape=(HEIGHT, WIDTH, NUM_CHANNEL))\n",
    "\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "x = Reshape((13*13*8,))(x)\n",
    "x = MMCLayer(3)(x)\n",
    "x = Dense(13*13*8, activation='relu')(x)\n",
    "x = Reshape((13, 13, 8))(x)\n",
    "\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 86 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "86/86 [==============================] - 7s 78ms/step - loss: 0.6779 - val_loss: 0.6372\n",
      "Epoch 2/100\n",
      "86/86 [==============================] - 5s 56ms/step - loss: 0.5175 - val_loss: 0.2453\n",
      "Epoch 3/100\n",
      "86/86 [==============================] - 4s 52ms/step - loss: 0.2126 - val_loss: 0.2172\n",
      "Epoch 4/100\n",
      "86/86 [==============================] - 5s 56ms/step - loss: 0.1718 - val_loss: 0.1625\n",
      "Epoch 5/100\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.1513 - val_loss: 0.1351\n",
      "Epoch 6/100\n",
      "86/86 [==============================] - 5s 60ms/step - loss: 0.1330 - val_loss: 0.1244\n",
      "Epoch 7/100\n",
      "86/86 [==============================] - 5s 63ms/step - loss: 0.1198 - val_loss: 0.1141\n",
      "Epoch 8/100\n",
      "86/86 [==============================] - 5s 62ms/step - loss: 0.1096 - val_loss: 0.1040\n",
      "Epoch 9/100\n",
      "86/86 [==============================] - 5s 60ms/step - loss: 0.1002 - val_loss: 0.0948\n",
      "Epoch 10/100\n",
      "86/86 [==============================] - 5s 60ms/step - loss: 0.0911 - val_loss: 0.0853\n",
      "Epoch 11/100\n",
      "86/86 [==============================] - 5s 59ms/step - loss: 0.0802 - val_loss: 0.0722\n",
      "Epoch 12/100\n",
      "86/86 [==============================] - 5s 57ms/step - loss: 0.0660 - val_loss: 0.0565\n",
      "Epoch 13/100\n",
      "86/86 [==============================] - 5s 59ms/step - loss: 0.0489 - val_loss: 0.0388\n",
      "Epoch 14/100\n",
      "86/86 [==============================] - 6s 74ms/step - loss: 0.0339 - val_loss: 0.0281\n",
      "Epoch 15/100\n",
      "86/86 [==============================] - 6s 70ms/step - loss: 0.0263 - val_loss: 0.0245\n",
      "Epoch 16/100\n",
      "86/86 [==============================] - 7s 76ms/step - loss: 0.0241 - val_loss: 0.0232\n",
      "Epoch 17/100\n",
      "86/86 [==============================] - 6s 73ms/step - loss: 0.0232 - val_loss: 0.0227\n",
      "Epoch 18/100\n",
      "86/86 [==============================] - 6s 71ms/step - loss: 0.0226 - val_loss: 0.0221\n",
      "Epoch 19/100\n",
      "86/86 [==============================] - 7s 77ms/step - loss: 0.0222 - val_loss: 0.0219\n",
      "Epoch 20/100\n",
      "86/86 [==============================] - 7s 79ms/step - loss: 0.0220 - val_loss: 0.0217\n",
      "Epoch 21/100\n",
      "86/86 [==============================] - 6s 71ms/step - loss: 0.0218 - val_loss: 0.0216\n",
      "Epoch 22/100\n",
      "86/86 [==============================] - 7s 78ms/step - loss: 0.0217 - val_loss: 0.0215\n",
      "Epoch 23/100\n",
      "86/86 [==============================] - 6s 70ms/step - loss: 0.0212 - val_loss: 0.0210\n",
      "Epoch 35/100\n",
      "86/86 [==============================] - 6s 69ms/step - loss: 0.0211 - val_loss: 0.0210\n",
      "Epoch 36/100\n",
      "86/86 [==============================] - 6s 68ms/step - loss: 0.0211 - val_loss: 0.0210\n",
      "Epoch 37/100\n",
      "86/86 [==============================] - 6s 70ms/step - loss: 0.0211 - val_loss: 0.0209\n",
      "Epoch 38/100\n",
      "86/86 [==============================] - 6s 69ms/step - loss: 0.0211 - val_loss: 0.0209\n",
      "Epoch 39/100\n",
      "86/86 [==============================] - 6s 68ms/step - loss: 0.0211 - val_loss: 0.0209\n",
      "Epoch 40/100\n",
      "86/86 [==============================] - 6s 71ms/step - loss: 0.0210 - val_loss: 0.0209\n",
      "Epoch 41/100\n",
      "86/86 [==============================] - 6s 68ms/step - loss: 0.0210 - val_loss: 0.0209\n",
      "Epoch 42/100\n",
      "86/86 [==============================] - 6s 73ms/step - loss: 0.0210 - val_loss: 0.0209\n",
      "Epoch 43/100\n",
      "86/86 [==============================] - 6s 75ms/step - loss: 0.0210 - val_loss: 0.0209\n",
      "Epoch 44/100\n",
      "86/86 [==============================] - 7s 79ms/step - loss: 0.0210 - val_loss: 0.0209\n",
      "Epoch 45/100\n",
      "86/86 [==============================] - 7s 76ms/step - loss: 0.0210 - val_loss: 0.0208\n",
      "Epoch 46/100\n",
      "86/86 [==============================] - 6s 74ms/step - loss: 0.0210 - val_loss: 0.0208\n",
      "Epoch 47/100\n",
      "86/86 [==============================] - 6s 68ms/step - loss: 0.0210 - val_loss: 0.0208\n",
      "Epoch 48/100\n",
      "86/86 [==============================] - 6s 68ms/step - loss: 0.0210 - val_loss: 0.0208\n",
      "Epoch 49/100\n",
      "86/86 [==============================] - 6s 67ms/step - loss: 0.0210 - val_loss: 0.0208\n",
      "Epoch 50/100\n",
      "86/86 [==============================] - 6s 70ms/step - loss: 0.0210 - val_loss: 0.0208\n",
      "Epoch 51/100\n",
      "86/86 [==============================] - 6s 69ms/step - loss: 0.0210 - val_loss: 0.0208\n",
      "Epoch 52/100\n",
      "86/86 [==============================] - 6s 68ms/step - loss: 0.0209 - val_loss: 0.0208\n",
      "Epoch 53/100\n",
      "86/86 [==============================] - 6s 71ms/step - loss: 0.0209 - val_loss: 0.0208\n",
      "Epoch 54/100\n",
      "86/86 [==============================] - 6s 70ms/step - loss: 0.0209 - val_loss: 0.0208\n",
      "Epoch 55/100\n",
      "86/86 [==============================] - 6s 71ms/step - loss: 0.0209 - val_loss: 0.0207\n",
      "Epoch 56/100\n",
      "86/86 [==============================] - 6s 68ms/step - loss: 0.0209 - val_loss: 0.0208\n",
      "Epoch 57/100\n",
      "86/86 [==============================] - 6s 68ms/step - loss: 0.0209 - val_loss: 0.0208\n",
      "Epoch 58/100\n",
      "86/86 [==============================] - 6s 67ms/step - loss: 0.0209 - val_loss: 0.0207\n",
      "Epoch 59/100\n",
      "86/86 [==============================] - 6s 69ms/step - loss: 0.0209 - val_loss: 0.0208\n",
      "Epoch 60/100\n",
      "86/86 [==============================] - 6s 72ms/step - loss: 0.0209 - val_loss: 0.0208\n",
      "Epoch 61/100\n",
      "86/86 [==============================] - 6s 72ms/step - loss: 0.0209 - val_loss: 0.0208\n",
      "Epoch 62/100\n",
      "86/86 [==============================] - 6s 72ms/step - loss: 0.0210 - val_loss: 0.0209\n",
      "Epoch 63/100\n",
      "86/86 [==============================] - 6s 74ms/step - loss: 0.0209 - val_loss: 0.0208\n",
      "Epoch 64/100\n",
      "86/86 [==============================] - 7s 78ms/step - loss: 0.0209 - val_loss: 0.0208\n",
      "Epoch 65/100\n",
      "86/86 [==============================] - 6s 74ms/step - loss: 0.0209 - val_loss: 0.0208\n",
      "Epoch 66/100\n",
      "86/86 [==============================] - 6s 72ms/step - loss: 0.0209 - val_loss: 0.0208\n",
      "Epoch 67/100\n",
      "86/86 [==============================] - 6s 73ms/step - loss: 0.0208 - val_loss: 0.0207\n",
      "Epoch 68/100\n",
      "86/86 [==============================] - 6s 72ms/step - loss: 0.0208 - val_loss: 0.0207\n",
      "Epoch 69/100\n",
      "86/86 [==============================] - 6s 72ms/step - loss: 0.0208 - val_loss: 0.0208\n",
      "Epoch 70/100\n",
      "86/86 [==============================] - 6s 72ms/step - loss: 0.0208 - val_loss: 0.0207\n",
      "Epoch 71/100\n",
      "86/86 [==============================] - 6s 70ms/step - loss: 0.0208 - val_loss: 0.0207\n",
      "Epoch 72/100\n",
      "86/86 [==============================] - 6s 73ms/step - loss: 0.0209 - val_loss: 0.0207\n",
      "Epoch 73/100\n",
      "86/86 [==============================] - 6s 72ms/step - loss: 0.0208 - val_loss: 0.0207\n",
      "Epoch 74/100\n",
      "86/86 [==============================] - 6s 74ms/step - loss: 0.0208 - val_loss: 0.0207\n",
      "Epoch 75/100\n",
      "86/86 [==============================] - 6s 72ms/step - loss: 0.0208 - val_loss: 0.0207\n",
      "Epoch 76/100\n",
      "86/86 [==============================] - 6s 69ms/step - loss: 0.0208 - val_loss: 0.0207\n",
      "Epoch 77/100\n",
      "86/86 [==============================] - 6s 73ms/step - loss: 0.0208 - val_loss: 0.0207\n",
      "Epoch 78/100\n",
      "86/86 [==============================] - 6s 73ms/step - loss: 0.0208 - val_loss: 0.0207\n",
      "Epoch 79/100\n",
      "86/86 [==============================] - 6s 72ms/step - loss: 0.0208 - val_loss: 0.0206\n",
      "Epoch 80/100\n",
      "86/86 [==============================] - 6s 67ms/step - loss: 0.0208 - val_loss: 0.0207\n",
      "Epoch 81/100\n",
      "86/86 [==============================] - 6s 72ms/step - loss: 0.0208 - val_loss: 0.0207\n",
      "Epoch 82/100\n",
      "86/86 [==============================] - 6s 70ms/step - loss: 0.0208 - val_loss: 0.0207\n",
      "Epoch 83/100\n",
      "86/86 [==============================] - 5s 61ms/step - loss: 0.0208 - val_loss: 0.0207\n",
      "Epoch 84/100\n",
      "86/86 [==============================] - 4s 46ms/step - loss: 0.0208 - val_loss: 0.0207\n",
      "Epoch 85/100\n",
      "86/86 [==============================] - 4s 45ms/step - loss: 0.0208 - val_loss: 0.0207\n",
      "Epoch 86/100\n",
      "86/86 [==============================] - 4s 45ms/step - loss: 0.0209 - val_loss: 0.0207\n",
      "Epoch 87/100\n",
      "86/86 [==============================] - 4s 49ms/step - loss: 0.0208 - val_loss: 0.0207\n",
      "Epoch 88/100\n",
      "86/86 [==============================] - 4s 51ms/step - loss: 0.0208 - val_loss: 0.0207\n",
      "Epoch 89/100\n",
      "86/86 [==============================] - 4s 46ms/step - loss: 0.0208 - val_loss: 0.0206\n",
      "Epoch 90/100\n",
      "86/86 [==============================] - 4s 46ms/step - loss: 0.0208 - val_loss: 0.0206\n",
      "Epoch 91/100\n",
      "86/86 [==============================] - 4s 45ms/step - loss: 0.0208 - val_loss: 0.0207\n",
      "Epoch 92/100\n",
      "86/86 [==============================] - 4s 47ms/step - loss: 0.0208 - val_loss: 0.0207\n",
      "Epoch 93/100\n",
      "86/86 [==============================] - 4s 46ms/step - loss: 0.0208 - val_loss: 0.0206\n",
      "Epoch 94/100\n",
      "86/86 [==============================] - 4s 46ms/step - loss: 0.0208 - val_loss: 0.0206\n",
      "Epoch 95/100\n",
      "86/86 [==============================] - 4s 45ms/step - loss: 0.0208 - val_loss: 0.0206\n",
      "Epoch 96/100\n",
      "86/86 [==============================] - 4s 45ms/step - loss: 0.0208 - val_loss: 0.0206\n",
      "Epoch 97/100\n",
      "86/86 [==============================] - 4s 45ms/step - loss: 0.0208 - val_loss: 0.0207\n",
      "Epoch 98/100\n",
      "86/86 [==============================] - 4s 46ms/step - loss: 0.0207 - val_loss: 0.0206\n",
      "Epoch 99/100\n",
      "86/86 [==============================] - 4s 46ms/step - loss: 0.0207 - val_loss: 0.0206\n",
      "Epoch 100/100\n",
      "86/86 [==============================] - 4s 45ms/step - loss: 0.0207 - val_loss: 0.0207\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2814f79eda0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dgen = DataGen(HEIGHT, WIDTH, NUM_CHANNEL)\n",
    "x, y = dgen.get_data(path=os.path.abspath(DATA_DIR),\n",
    "                     target_mmc_out=False,\n",
    "                     size=8,\n",
    "                     channel_first=False)\n",
    "\n",
    "x = x / 255.\n",
    "y = y / 255.\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, shuffle=True)\n",
    "\n",
    "autoencoder.fit(x_train, y_train,\n",
    "                epochs=100,\n",
    "                batch_size=10,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs = autoencoder.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 5\n",
    "\n",
    "fig, axes = plt.subplots(figsize=((10, 3)), nrows=1, ncols=NUM_CHANNEL+2)\n",
    "\n",
    "# display input images\n",
    "for i, ax in enumerate(axes.flat[:NUM_CHANNEL]):\n",
    "    ax.imshow(x_test[idx][:, :, i].reshape(HEIGHT, WIDTH), cmap='gray')\n",
    "    ax.axis('off'), ax.set_title('step ' + str(i+1))\n",
    "    \n",
    "# display prediction\n",
    "axes[NUM_CHANNEL].imshow(decoded_imgs[idx][:, :, 0].reshape(HEIGHT, WIDTH), cmap='gray')\n",
    "axes[NUM_CHANNEL].axis('off'), axes[NUM_CHANNEL].set_title('predicted')\n",
    "\n",
    "# display target\n",
    "axes[NUM_CHANNEL+1].imshow(y_test[idx][:, :, 0].reshape(HEIGHT, WIDTH), cmap='gray')\n",
    "axes[NUM_CHANNEL+1].axis('off'), axes[NUM_CHANNEL+1].set_title('target')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
