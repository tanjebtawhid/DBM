{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "%matplotlib inline\n",
    "\n",
    "import keras\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Lambda, Reshape, Flatten, ZeroPadding2D, Layer\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from simple_movement import DataGen, SimpleMovement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = 'C:\\\\Users\\\\ttanj\\\\UoB\\\\WS18\\\\DBM\\\\data\\data_simple_movement'\n",
    "HEIGHT = 100\n",
    "WIDTH = 100\n",
    "NUM_CHANNEL = 2\n",
    "RGB = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mmc(x):\n",
    "    df = 1 / 5\n",
    "    w = np.array([\n",
    "        [1, df, 0], [-1, 0, 1], [0, 0, 1]\n",
    "    ])\n",
    "    return K.dot(x, K.constant(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MMCLayer(Layer):\n",
    "    \n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        super(MMCLayer, self).__init__(**kwargs)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(name='kernel',\n",
    "                                     shape=(input_shape[1], self.output_dim),\n",
    "                                     initializer='uniform',\n",
    "                                     trainable=True)\n",
    "        super(MMCLayer, self).build(input_shape)\n",
    "        \n",
    "    def call(self, x):\n",
    "        df = 1 / 5\n",
    "        w = np.array([\n",
    "            [1, df, 0], [-1, 0, 1], [0, 0, 1]\n",
    "        ])\n",
    "        return K.dot(K.dot(x, self.kernel), K.constant(w))\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 100, 100, 2)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 100, 100, 16)      304       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 50, 50, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 50, 50, 8)         1160      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 25, 25, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 25, 25, 8)         584       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 13, 13, 8)         0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 1352)              0         \n",
      "_________________________________________________________________\n",
      "mmc_layer_1 (MMCLayer)       (None, 3)                 4056      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1352)              5408      \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 13, 13, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 8)         584       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 26, 26, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 26, 26, 8)         584       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 52, 52, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 50, 50, 16)        1168      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 100, 100, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 100, 100, 1)       145       \n",
      "=================================================================\n",
      "Total params: 13,993\n",
      "Trainable params: 13,993\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_img = Input(shape=(HEIGHT, WIDTH, NUM_CHANNEL))\n",
    "\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "x = Reshape((13*13*8,))(x)\n",
    "# x = Dense(3, activation='relu')(x)\n",
    "# x = Lambda(mmc)(x)\n",
    "x = MMCLayer(3)(x)\n",
    "x = Dense(13*13*8, activation='relu')(x)\n",
    "x = Reshape((13, 13, 8))(x)\n",
    "\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 194 samples, validate on 22 samples\n",
      "Epoch 1/100\n",
      "194/194 [==============================] - 6s 33ms/step - loss: 0.4372 - val_loss: 0.2271\n",
      "Epoch 2/100\n",
      "194/194 [==============================] - 5s 28ms/step - loss: 0.1588 - val_loss: 0.1307\n",
      "Epoch 3/100\n",
      "194/194 [==============================] - 6s 30ms/step - loss: 0.1186 - val_loss: 0.1061\n",
      "Epoch 4/100\n",
      "194/194 [==============================] - 7s 36ms/step - loss: 0.0973 - val_loss: 0.0865\n",
      "Epoch 5/100\n",
      "194/194 [==============================] - 7s 34ms/step - loss: 0.0772 - val_loss: 0.0666\n",
      "Epoch 6/100\n",
      "194/194 [==============================] - 7s 36ms/step - loss: 0.0585 - val_loss: 0.0483\n",
      "Epoch 7/100\n",
      "194/194 [==============================] - 7s 34ms/step - loss: 0.0401 - val_loss: 0.0317\n",
      "Epoch 8/100\n",
      "194/194 [==============================] - 7s 36ms/step - loss: 0.0284 - val_loss: 0.0255\n",
      "Epoch 9/100\n",
      "194/194 [==============================] - 7s 38ms/step - loss: 0.0246 - val_loss: 0.0239\n",
      "Epoch 10/100\n",
      "194/194 [==============================] - 7s 36ms/step - loss: 0.0235 - val_loss: 0.0229\n",
      "Epoch 11/100\n",
      "194/194 [==============================] - 6s 33ms/step - loss: 0.0229 - val_loss: 0.0226\n",
      "Epoch 12/100\n",
      "194/194 [==============================] - 6s 33ms/step - loss: 0.0226 - val_loss: 0.0225\n",
      "Epoch 13/100\n",
      "194/194 [==============================] - 6s 33ms/step - loss: 0.0223 - val_loss: 0.0222\n",
      "Epoch 14/100\n",
      "194/194 [==============================] - 6s 33ms/step - loss: 0.0222 - val_loss: 0.0220\n",
      "Epoch 15/100\n",
      "194/194 [==============================] - 7s 34ms/step - loss: 0.0221 - val_loss: 0.0219\n",
      "Epoch 16/100\n",
      "194/194 [==============================] - 6s 33ms/step - loss: 0.0219 - val_loss: 0.0218\n",
      "Epoch 17/100\n",
      "194/194 [==============================] - 6s 33ms/step - loss: 0.0219 - val_loss: 0.0218\n",
      "Epoch 18/100\n",
      "194/194 [==============================] - 6s 33ms/step - loss: 0.0217 - val_loss: 0.0217\n",
      "Epoch 19/100\n",
      "194/194 [==============================] - 6s 33ms/step - loss: 0.0217 - val_loss: 0.0216\n",
      "Epoch 20/100\n",
      "194/194 [==============================] - 6s 33ms/step - loss: 0.0216 - val_loss: 0.0215\n",
      "Epoch 21/100\n",
      "194/194 [==============================] - 6s 33ms/step - loss: 0.0216 - val_loss: 0.0215\n",
      "Epoch 22/100\n",
      "194/194 [==============================] - 6s 33ms/step - loss: 0.0216 - val_loss: 0.0215\n",
      "Epoch 23/100\n",
      "194/194 [==============================] - 7s 34ms/step - loss: 0.0214 - val_loss: 0.0214\n",
      "Epoch 24/100\n",
      "194/194 [==============================] - 7s 38ms/step - loss: 0.0214 - val_loss: 0.0214\n",
      "Epoch 25/100\n",
      "194/194 [==============================] - 7s 35ms/step - loss: 0.0214 - val_loss: 0.0213\n",
      "Epoch 26/100\n",
      "194/194 [==============================] - 7s 35ms/step - loss: 0.0214 - val_loss: 0.0213\n",
      "Epoch 27/100\n",
      "194/194 [==============================] - 7s 36ms/step - loss: 0.0213 - val_loss: 0.0213\n",
      "Epoch 28/100\n",
      "194/194 [==============================] - 7s 36ms/step - loss: 0.0213 - val_loss: 0.0213\n",
      "Epoch 29/100\n",
      "194/194 [==============================] - 8s 39ms/step - loss: 0.0213 - val_loss: 0.0212\n",
      "Epoch 30/100\n",
      "194/194 [==============================] - 7s 34ms/step - loss: 0.0212 - val_loss: 0.0212\n",
      "Epoch 31/100\n",
      "194/194 [==============================] - 6s 33ms/step - loss: 0.0212 - val_loss: 0.0212\n",
      "Epoch 32/100\n",
      "194/194 [==============================] - 7s 35ms/step - loss: 0.0212 - val_loss: 0.0212\n",
      "Epoch 33/100\n",
      "194/194 [==============================] - 7s 35ms/step - loss: 0.0212 - val_loss: 0.0213\n",
      "Epoch 34/100\n",
      "194/194 [==============================] - 8s 39ms/step - loss: 0.0212 - val_loss: 0.0211\n",
      "Epoch 35/100\n",
      "194/194 [==============================] - 7s 37ms/step - loss: 0.0212 - val_loss: 0.0211\n",
      "Epoch 36/100\n",
      "194/194 [==============================] - 8s 42ms/step - loss: 0.0212 - val_loss: 0.0212\n",
      "Epoch 37/100\n",
      "194/194 [==============================] - 7s 36ms/step - loss: 0.0212 - val_loss: 0.0211\n",
      "Epoch 38/100\n",
      "194/194 [==============================] - 7s 36ms/step - loss: 0.0211 - val_loss: 0.0211\n",
      "Epoch 39/100\n",
      "194/194 [==============================] - 7s 35ms/step - loss: 0.0211 - val_loss: 0.0211\n",
      "Epoch 40/100\n",
      "194/194 [==============================] - 7s 37ms/step - loss: 0.0211 - val_loss: 0.0211\n",
      "Epoch 41/100\n",
      "194/194 [==============================] - 7s 38ms/step - loss: 0.0212 - val_loss: 0.0211\n",
      "Epoch 42/100\n",
      "194/194 [==============================] - 7s 38ms/step - loss: 0.0211 - val_loss: 0.0211\n",
      "Epoch 43/100\n",
      "194/194 [==============================] - 6s 33ms/step - loss: 0.0211 - val_loss: 0.0210\n",
      "Epoch 44/100\n",
      "194/194 [==============================] - 7s 37ms/step - loss: 0.0211 - val_loss: 0.0211\n",
      "Epoch 45/100\n",
      "194/194 [==============================] - 7s 34ms/step - loss: 0.0211 - val_loss: 0.0210\n",
      "Epoch 46/100\n",
      "194/194 [==============================] - 7s 37ms/step - loss: 0.0211 - val_loss: 0.0211\n",
      "Epoch 47/100\n",
      "194/194 [==============================] - 8s 40ms/step - loss: 0.0211 - val_loss: 0.0211\n",
      "Epoch 48/100\n",
      "194/194 [==============================] - 7s 35ms/step - loss: 0.0211 - val_loss: 0.0212\n",
      "Epoch 49/100\n",
      "194/194 [==============================] - 7s 34ms/step - loss: 0.0211 - val_loss: 0.0210\n",
      "Epoch 50/100\n",
      "194/194 [==============================] - 6s 33ms/step - loss: 0.0211 - val_loss: 0.0211\n",
      "Epoch 51/100\n",
      "194/194 [==============================] - 7s 34ms/step - loss: 0.0211 - val_loss: 0.0211\n",
      "Epoch 52/100\n",
      "194/194 [==============================] - 7s 36ms/step - loss: 0.0211 - val_loss: 0.0210\n",
      "Epoch 53/100\n",
      "194/194 [==============================] - 7s 34ms/step - loss: 0.0211 - val_loss: 0.0211\n",
      "Epoch 54/100\n",
      "194/194 [==============================] - 7s 36ms/step - loss: 0.0211 - val_loss: 0.0210\n",
      "Epoch 55/100\n",
      "194/194 [==============================] - 8s 39ms/step - loss: 0.0210 - val_loss: 0.0211\n",
      "Epoch 56/100\n",
      "194/194 [==============================] - 8s 39ms/step - loss: 0.0211 - val_loss: 0.0210\n",
      "Epoch 57/100\n",
      "194/194 [==============================] - 7s 34ms/step - loss: 0.0210 - val_loss: 0.0210\n",
      "Epoch 58/100\n",
      "194/194 [==============================] - 7s 36ms/step - loss: 0.0210 - val_loss: 0.0210\n",
      "Epoch 59/100\n",
      "194/194 [==============================] - 9s 48ms/step - loss: 0.0211 - val_loss: 0.0210\n",
      "Epoch 60/100\n",
      "194/194 [==============================] - 7s 38ms/step - loss: 0.0211 - val_loss: 0.0210\n",
      "Epoch 61/100\n",
      "194/194 [==============================] - 8s 40ms/step - loss: 0.0211 - val_loss: 0.0210\n",
      "Epoch 62/100\n",
      "194/194 [==============================] - 7s 35ms/step - loss: 0.0211 - val_loss: 0.0210\n",
      "Epoch 63/100\n",
      "194/194 [==============================] - 7s 35ms/step - loss: 0.0210 - val_loss: 0.0210\n",
      "Epoch 64/100\n",
      "194/194 [==============================] - 6s 33ms/step - loss: 0.0211 - val_loss: 0.0211\n",
      "Epoch 65/100\n",
      "194/194 [==============================] - 7s 37ms/step - loss: 0.0210 - val_loss: 0.0209\n",
      "Epoch 66/100\n",
      "194/194 [==============================] - 7s 34ms/step - loss: 0.0210 - val_loss: 0.0210\n",
      "Epoch 67/100\n",
      "194/194 [==============================] - 7s 36ms/step - loss: 0.0210 - val_loss: 0.0210\n",
      "Epoch 68/100\n",
      "194/194 [==============================] - 7s 34ms/step - loss: 0.0210 - val_loss: 0.0210\n",
      "Epoch 69/100\n",
      "194/194 [==============================] - 7s 34ms/step - loss: 0.0210 - val_loss: 0.0210\n",
      "Epoch 70/100\n",
      "194/194 [==============================] - 7s 34ms/step - loss: 0.0210 - val_loss: 0.0210\n",
      "Epoch 71/100\n",
      "194/194 [==============================] - 7s 36ms/step - loss: 0.0210 - val_loss: 0.0211\n",
      "Epoch 72/100\n",
      "194/194 [==============================] - 7s 36ms/step - loss: 0.0209 - val_loss: 0.0210\n",
      "Epoch 73/100\n",
      "194/194 [==============================] - 7s 34ms/step - loss: 0.0210 - val_loss: 0.0210\n",
      "Epoch 74/100\n",
      "194/194 [==============================] - 7s 38ms/step - loss: 0.0210 - val_loss: 0.0210\n",
      "Epoch 75/100\n",
      "194/194 [==============================] - 7s 35ms/step - loss: 0.0210 - val_loss: 0.0210\n",
      "Epoch 76/100\n",
      "194/194 [==============================] - 7s 38ms/step - loss: 0.0210 - val_loss: 0.0210\n",
      "Epoch 77/100\n",
      "194/194 [==============================] - 8s 39ms/step - loss: 0.0210 - val_loss: 0.0210\n",
      "Epoch 78/100\n",
      "194/194 [==============================] - 7s 37ms/step - loss: 0.0210 - val_loss: 0.0210\n",
      "Epoch 79/100\n",
      "194/194 [==============================] - 7s 34ms/step - loss: 0.0210 - val_loss: 0.0209\n",
      "Epoch 80/100\n",
      "194/194 [==============================] - 7s 35ms/step - loss: 0.0210 - val_loss: 0.0210\n",
      "Epoch 81/100\n",
      "194/194 [==============================] - 7s 37ms/step - loss: 0.0210 - val_loss: 0.0209\n",
      "Epoch 82/100\n",
      "194/194 [==============================] - 7s 38ms/step - loss: 0.0210 - val_loss: 0.0209\n",
      "Epoch 83/100\n",
      "194/194 [==============================] - 7s 38ms/step - loss: 0.0210 - val_loss: 0.0210\n",
      "Epoch 84/100\n",
      "194/194 [==============================] - 7s 36ms/step - loss: 0.0210 - val_loss: 0.0209\n",
      "Epoch 85/100\n",
      "194/194 [==============================] - 8s 39ms/step - loss: 0.0210 - val_loss: 0.0210\n",
      "Epoch 86/100\n",
      "194/194 [==============================] - 7s 39ms/step - loss: 0.0210 - val_loss: 0.0209\n",
      "Epoch 87/100\n",
      "194/194 [==============================] - 8s 39ms/step - loss: 0.0210 - val_loss: 0.0209\n",
      "Epoch 88/100\n",
      "194/194 [==============================] - 7s 36ms/step - loss: 0.0210 - val_loss: 0.0209\n",
      "Epoch 89/100\n",
      "194/194 [==============================] - 8s 39ms/step - loss: 0.0210 - val_loss: 0.0209\n",
      "Epoch 90/100\n",
      "194/194 [==============================] - 7s 37ms/step - loss: 0.0210 - val_loss: 0.0209\n",
      "Epoch 91/100\n",
      "194/194 [==============================] - 7s 37ms/step - loss: 0.0209 - val_loss: 0.0210\n",
      "Epoch 92/100\n",
      "194/194 [==============================] - 7s 36ms/step - loss: 0.0210 - val_loss: 0.0210\n",
      "Epoch 93/100\n",
      "194/194 [==============================] - 7s 38ms/step - loss: 0.0209 - val_loss: 0.0209\n",
      "Epoch 94/100\n",
      "194/194 [==============================] - 7s 38ms/step - loss: 0.0209 - val_loss: 0.0209\n",
      "Epoch 95/100\n",
      "194/194 [==============================] - 7s 37ms/step - loss: 0.0210 - val_loss: 0.0209\n",
      "Epoch 96/100\n",
      "194/194 [==============================] - 8s 39ms/step - loss: 0.0210 - val_loss: 0.0210\n",
      "Epoch 97/100\n",
      "194/194 [==============================] - 7s 37ms/step - loss: 0.0210 - val_loss: 0.0209\n",
      "Epoch 98/100\n",
      "194/194 [==============================] - 7s 36ms/step - loss: 0.0210 - val_loss: 0.0209\n",
      "Epoch 99/100\n",
      "194/194 [==============================] - 7s 36ms/step - loss: 0.0210 - val_loss: 0.0209\n",
      "Epoch 100/100\n",
      "194/194 [==============================] - 7s 38ms/step - loss: 0.0209 - val_loss: 0.0209\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f91bc5deb8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dgen = DataGen(HEIGHT, WIDTH, NUM_CHANNEL)\n",
    "x, y = dgen.prepare_data()\n",
    "\n",
    "x = x / 255.\n",
    "y = y / 255.\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, shuffle=True)\n",
    "\n",
    "autoencoder.fit(x_train, y_train,\n",
    "                epochs=100,\n",
    "                batch_size=10,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs = autoencoder.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 0\n",
    "\n",
    "plt.figure(figsize=(10, 3))\n",
    "\n",
    "# display original\n",
    "ax = plt.subplot(1, 4, 1)\n",
    "plt.imshow(x_test[idx][:, :, 0].reshape(HEIGHT, WIDTH))\n",
    "plt.gray()\n",
    "ax.get_xaxis().set_visible(False)\n",
    "ax.get_yaxis().set_visible(False)\n",
    "\n",
    "ax = plt.subplot(1, 4, 2)\n",
    "plt.imshow(x_test[idx][:, :, 1].reshape(HEIGHT, WIDTH))\n",
    "plt.gray()\n",
    "ax.get_xaxis().set_visible(False)\n",
    "ax.get_yaxis().set_visible(False)\n",
    "\n",
    "# display reconstruction\n",
    "ax = plt.subplot(1, 4, 3)\n",
    "plt.imshow(decoded_imgs[idx][:, :, 0].reshape(HEIGHT, WIDTH))\n",
    "plt.gray()\n",
    "ax.get_xaxis().set_visible(False)\n",
    "ax.get_yaxis().set_visible(False)\n",
    "\n",
    "ax = plt.subplot(1, 4, 4)\n",
    "plt.imshow(y_test[idx][:, :, 0].reshape(HEIGHT, WIDTH))\n",
    "plt.gray()\n",
    "ax.get_xaxis().set_visible(False)\n",
    "ax.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
