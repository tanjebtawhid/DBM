{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchsummary import summary\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from data_generator import DataGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MMC(nn.Module):\n",
    "    \n",
    "    def __init__(self, beta=5, num_iter=20):\n",
    "        super(MMC, self).__init__()\n",
    "        self.df = 1. / beta\n",
    "        self.num_iter = num_iter\n",
    "        # self.weights = nn.Parameter(data= torch.tensor([[1, self.df, 0], [-1, 0, 1], [0, 0, 1]]),\n",
    "        #                            requires_grad=False)\n",
    "        self.weights = nn.Parameter(data=torch.from_numpy(self._init_weights()).float(), \n",
    "                                    requires_grad=False)\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        w = np.array([[1, self.df, 0], [-1, 0, 1], [0, 0, 1]])\n",
    "        return np.broadcast_to(w, (9, 3, 3))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.bmm(torch.pow(self.weights, self.num_iter), x.unsqueeze(2)).squeeze(2)\n",
    "        # x = torch.matmul(self.weights, x.transpose_(0, 1))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_channel):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=num_channel, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 8, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(8, 8, 3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(8, 8, 2)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(200, 128)\n",
    "        self.fc2 = nn.Linear(128, 3)\n",
    "        self.mmc = MMC()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = self.pool(F.relu(self.conv4(x)))\n",
    "        x = x.view(-1, 5*5*8)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        # print('before: ', x)\n",
    "        x = self.mmc(x)\n",
    "        # print('after: ', x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight torch.Size([16, 1, 3, 3])\n",
      "conv1.bias torch.Size([16])\n",
      "conv2.weight torch.Size([8, 16, 3, 3])\n",
      "conv2.bias torch.Size([8])\n",
      "conv3.weight torch.Size([8, 8, 3, 3])\n",
      "conv3.bias torch.Size([8])\n",
      "conv4.weight torch.Size([8, 8, 2, 2])\n",
      "conv4.bias torch.Size([8])\n",
      "fc1.weight torch.Size([128, 200])\n",
      "fc1.bias torch.Size([128])\n",
      "fc2.weight torch.Size([3, 128])\n",
      "fc2.bias torch.Size([3])\n",
      "mmc.weights torch.Size([9, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "model = Encoder(1)\n",
    "for n, p in model.named_parameters():\n",
    "    print(n, p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary(model, (1, 100, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(num_channel):\n",
    "    \n",
    "    net = Encoder(num_channel=num_channel)\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "    \n",
    "    return net, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tensor(x):\n",
    "    return torch.from_numpy(x).float()\n",
    "\n",
    "def get_data(height, width, num_channel, path, size, bs):\n",
    "    \n",
    "    dgen = DataGen(height, width, num_channel)\n",
    "    x, y = dgen.get_data(path, True, size, True)\n",
    "    print('Data loaded...\\nx:{}\\ty:{}\\n'.format(x.shape, y.shape))\n",
    "    \n",
    "    x = x / 255.\n",
    "    x = x[:90]\n",
    "    y = y[:90]\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, shuffle=True)\n",
    "    x_train, x_test, y_train, y_test = map(to_tensor, (x_train, x_test, y_train, y_test))\n",
    "    \n",
    "    train_ds = TensorDataset(x_train, y_train)\n",
    "    train_dl = DataLoader(train_ds, batch_size=bs, shuffle=True)\n",
    "\n",
    "    test_ds = TensorDataset(x_test, y_test)\n",
    "    test_dl = DataLoader(test_ds, batch_size=bs)\n",
    "    \n",
    "    return train_dl, test_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_flow(named_parameters):\n",
    "    ave_grads = []\n",
    "    max_grads= []\n",
    "    layers = []\n",
    "    for n, p in named_parameters:\n",
    "        if(p.requires_grad) and (\"bias\" not in n):\n",
    "            layers.append(n)\n",
    "            ave_grads.append(p.grad.abs().mean())\n",
    "            max_grads.append(p.grad.abs().max())\n",
    "    print('layers: {}'.format(layers))\n",
    "    print('max: {}'.format(max_grads))\n",
    "    print('mean: {}\\n\\n'.format( ave_grads))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(net, optimizer, train_dl, test_dl, epochs):\n",
    "    \n",
    "    loss_function = nn.MSELoss()\n",
    "    for epoch in range(epochs):\n",
    "        net.train()\n",
    "        for x, y in train_dl:\n",
    "            pred = net(x)\n",
    "            loss = loss_function(pred, y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            # grad_flow(net.named_parameters())\n",
    "            optimizer.step()\n",
    "\n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "            test_loss = sum(loss_function(net(x), y) for x, y in test_dl)\n",
    "        print('epoch:{}, test_loss:{}'.format(epoch+1, test_loss/len(test_dl)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = './data/data_simple_movement/cartesian/'\n",
    "HEIGHT = 100\n",
    "WIDTH = 100\n",
    "NUM_CHANNEL = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded...\n",
      "x:(96, 2, 100, 100)\ty:(96, 3)\n",
      "\n",
      "epoch:1, test_loss:0.16507582366466522\n",
      "epoch:2, test_loss:0.1658763438463211\n",
      "epoch:3, test_loss:0.16412250697612762\n",
      "epoch:4, test_loss:0.16304783523082733\n",
      "epoch:5, test_loss:0.16334226727485657\n",
      "epoch:6, test_loss:0.1647080034017563\n",
      "epoch:7, test_loss:0.16266800463199615\n",
      "epoch:8, test_loss:0.16278061270713806\n",
      "epoch:9, test_loss:0.1632707118988037\n",
      "epoch:10, test_loss:0.15794607996940613\n",
      "epoch:11, test_loss:0.15149512887001038\n",
      "epoch:12, test_loss:0.15696869790554047\n",
      "epoch:13, test_loss:0.14606626331806183\n",
      "epoch:14, test_loss:0.1465470790863037\n",
      "epoch:15, test_loss:0.16499516367912292\n",
      "epoch:16, test_loss:0.15720269083976746\n",
      "epoch:17, test_loss:0.12926284968852997\n",
      "epoch:18, test_loss:0.12916569411754608\n",
      "epoch:19, test_loss:0.14382973313331604\n",
      "epoch:20, test_loss:0.12743353843688965\n",
      "epoch:21, test_loss:0.1272801160812378\n",
      "epoch:22, test_loss:0.12498456239700317\n",
      "epoch:23, test_loss:0.13436101377010345\n",
      "epoch:24, test_loss:0.12304960191249847\n",
      "epoch:25, test_loss:0.12253174185752869\n",
      "epoch:26, test_loss:0.13083425164222717\n",
      "epoch:27, test_loss:0.12104686349630356\n",
      "epoch:28, test_loss:0.1226111501455307\n",
      "epoch:29, test_loss:0.11778487265110016\n",
      "epoch:30, test_loss:0.11605552583932877\n",
      "epoch:31, test_loss:0.12501148879528046\n",
      "epoch:32, test_loss:0.119057297706604\n",
      "epoch:33, test_loss:0.11677752435207367\n",
      "epoch:34, test_loss:0.12422027438879013\n",
      "epoch:35, test_loss:0.11848748475313187\n",
      "epoch:36, test_loss:0.11451565474271774\n",
      "epoch:37, test_loss:0.11579620838165283\n",
      "epoch:38, test_loss:0.11545418947935104\n",
      "epoch:39, test_loss:0.12015040963888168\n",
      "epoch:40, test_loss:0.11488579213619232\n",
      "epoch:41, test_loss:0.11400067061185837\n",
      "epoch:42, test_loss:0.11305350065231323\n",
      "epoch:43, test_loss:0.11457085609436035\n",
      "epoch:44, test_loss:0.1144627034664154\n",
      "epoch:45, test_loss:0.1131768599152565\n",
      "epoch:46, test_loss:0.11695845425128937\n",
      "epoch:47, test_loss:0.11387558281421661\n",
      "epoch:48, test_loss:0.11308892071247101\n",
      "epoch:49, test_loss:0.11399607360363007\n",
      "epoch:50, test_loss:0.11907459795475006\n",
      "epoch:51, test_loss:0.11285676062107086\n",
      "epoch:52, test_loss:0.12170476466417313\n",
      "epoch:53, test_loss:0.11287368834018707\n",
      "epoch:54, test_loss:0.11444184929132462\n",
      "epoch:55, test_loss:0.1148359403014183\n",
      "epoch:56, test_loss:0.11455186456441879\n",
      "epoch:57, test_loss:0.11842364072799683\n",
      "epoch:58, test_loss:0.11448962986469269\n",
      "epoch:59, test_loss:0.11711659282445908\n",
      "epoch:60, test_loss:0.11404867470264435\n",
      "epoch:61, test_loss:0.11637285351753235\n",
      "epoch:62, test_loss:0.11385487020015717\n",
      "epoch:63, test_loss:0.1152619943022728\n",
      "epoch:64, test_loss:0.11455699056386948\n",
      "epoch:65, test_loss:0.1141643300652504\n",
      "epoch:66, test_loss:0.1142473965883255\n",
      "epoch:67, test_loss:0.11301194131374359\n",
      "epoch:68, test_loss:0.11641630530357361\n",
      "epoch:69, test_loss:0.11369510740041733\n",
      "epoch:70, test_loss:0.11246445029973984\n",
      "epoch:71, test_loss:0.11368611454963684\n",
      "epoch:72, test_loss:0.11332473903894424\n",
      "epoch:73, test_loss:0.11572591215372086\n",
      "epoch:74, test_loss:0.11340048909187317\n",
      "epoch:75, test_loss:0.11371804773807526\n",
      "epoch:76, test_loss:0.11690502613782883\n",
      "epoch:77, test_loss:0.1143898293375969\n",
      "epoch:78, test_loss:0.11588197201490402\n",
      "epoch:79, test_loss:0.11439303308725357\n",
      "epoch:80, test_loss:0.11386037617921829\n",
      "epoch:81, test_loss:0.11325249075889587\n",
      "epoch:82, test_loss:0.1128997877240181\n",
      "epoch:83, test_loss:0.11371171474456787\n",
      "epoch:84, test_loss:0.11304020881652832\n",
      "epoch:85, test_loss:0.11440723389387131\n",
      "epoch:86, test_loss:0.11459755152463913\n",
      "epoch:87, test_loss:0.11297748982906342\n",
      "epoch:88, test_loss:0.11533065885305405\n",
      "epoch:89, test_loss:0.11252915114164352\n",
      "epoch:90, test_loss:0.11506614834070206\n",
      "epoch:91, test_loss:0.11336573213338852\n",
      "epoch:92, test_loss:0.11307688802480698\n",
      "epoch:93, test_loss:0.11393624544143677\n",
      "epoch:94, test_loss:0.11301448941230774\n",
      "epoch:95, test_loss:0.11375411599874496\n",
      "epoch:96, test_loss:0.11331115663051605\n",
      "epoch:97, test_loss:0.11366831511259079\n",
      "epoch:98, test_loss:0.1124303787946701\n",
      "epoch:99, test_loss:0.11261478811502457\n",
      "epoch:100, test_loss:0.11191748827695847\n"
     ]
    }
   ],
   "source": [
    "net, optimizer = get_model(num_channel=2)\n",
    "\n",
    "train_dl, test_dl = get_data(\n",
    "    height=HEIGHT, \n",
    "    width=WIDTH,\n",
    "    num_channel=NUM_CHANNEL,\n",
    "    path=DATA_DIR,\n",
    "    size=8,\n",
    "    bs=9\n",
    ")\n",
    "\n",
    "fit(net, optimizer, train_dl, test_dl, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: tensor([[ 0.1777,  0.3377,  0.1600],\n",
      "        [ 0.2895,  0.5750,  0.2855],\n",
      "        [-0.2511, -0.5110, -0.2599],\n",
      "        [-0.1816, -0.3755, -0.1940],\n",
      "        [ 0.0409,  0.0696,  0.0288],\n",
      "        [ 0.1577,  0.3003,  0.1425],\n",
      "        [-0.0832, -0.1816, -0.0984],\n",
      "        [ 0.0843,  0.1548,  0.0705],\n",
      "        [-0.0112, -0.0354, -0.0242]], grad_fn=<SqueezeBackward1>), target: tensor([[ 5.0227e-01,  3.6272e-03,  5.0000e-01],\n",
      "        [ 8.6668e-01,  1.8136e-03,  8.6603e-01],\n",
      "        [-8.6273e-01,  9.0679e-03, -8.6603e-01],\n",
      "        [-2.5438e-01,  6.3475e-03, -2.5882e-01],\n",
      "        [ 3.9369e-03,  5.4407e-03,  6.1232e-17],\n",
      "        [ 5.0227e-01,  3.6272e-03,  5.0000e-01],\n",
      "        [-2.5438e-01,  6.3475e-03, -2.5882e-01],\n",
      "        [ 2.6199e-01,  4.5339e-03,  2.5882e-01],\n",
      "        [ 3.9369e-03,  5.4407e-03,  6.1232e-17]])\n"
     ]
    }
   ],
   "source": [
    "for x, y in test_dl:\n",
    "    print('prediction: {}, target: {}'.format(net(x), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.04966],\n",
       "       [ 0.0709 ],\n",
       "       [ 0.0237 ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[-0.0472], [-0.0123],  [0.0237]])\n",
    "b = np.array([[1, 0.2, 0], [-1, 0, 1], [0, 0, 1]])\n",
    "np.dot(b, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#         iteration = 0\n",
    "#         while iteration < self.num_iter:\n",
    "#             for i in range(x.shape[0]):\n",
    "#                 x[i] = torch.matmul(self.weights, x[i])\n",
    "#             iteration += 1\n",
    "        # x = torch.acos(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[1, 2, 3]])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [2],\n",
       "        [3]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.transpose(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
