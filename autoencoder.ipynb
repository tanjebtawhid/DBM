{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "%matplotlib inline\n",
    "\n",
    "import keras\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from data_generator import DataGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = './data/data_simple_movement_1/'\n",
    "HEIGHT = 100\n",
    "WIDTH = 100\n",
    "NUM_CHANNEL = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 100, 100, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 100, 100, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 50, 50, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 50, 50, 8)         1160      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 25, 25, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 25, 25, 8)         584       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 13, 13, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 8)         584       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 26, 26, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 26, 26, 8)         584       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 52, 52, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 50, 50, 16)        1168      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 100, 100, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 100, 100, 1)       145       \n",
      "=================================================================\n",
      "Total params: 4,673\n",
      "Trainable params: 4,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_img = Input(shape=(HEIGHT, WIDTH, NUM_CHANNEL))\n",
    "\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 86 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "86/86 [==============================] - 3s 39ms/step - loss: 0.5728 - val_loss: 0.3371\n",
      "Epoch 2/100\n",
      "86/86 [==============================] - 3s 30ms/step - loss: 0.2188 - val_loss: 0.2151\n",
      "Epoch 3/100\n",
      "86/86 [==============================] - 3s 30ms/step - loss: 0.2028 - val_loss: 0.1672\n",
      "Epoch 4/100\n",
      "86/86 [==============================] - 3s 29ms/step - loss: 0.1638 - val_loss: 0.1630\n",
      "Epoch 5/100\n",
      "86/86 [==============================] - 3s 31ms/step - loss: 0.1590 - val_loss: 0.1568\n",
      "Epoch 6/100\n",
      "86/86 [==============================] - 3s 30ms/step - loss: 0.1533 - val_loss: 0.1504\n",
      "Epoch 7/100\n",
      "86/86 [==============================] - 3s 31ms/step - loss: 0.1468 - val_loss: 0.1430\n",
      "Epoch 8/100\n",
      "86/86 [==============================] - 3s 31ms/step - loss: 0.1390 - val_loss: 0.1348\n",
      "Epoch 9/100\n",
      "86/86 [==============================] - 2s 29ms/step - loss: 0.1307 - val_loss: 0.1258\n",
      "Epoch 10/100\n",
      "86/86 [==============================] - 3s 31ms/step - loss: 0.1216 - val_loss: 0.1166\n",
      "Epoch 11/100\n",
      "86/86 [==============================] - 4s 44ms/step - loss: 0.1125 - val_loss: 0.1080\n",
      "Epoch 12/100\n",
      "86/86 [==============================] - 3s 39ms/step - loss: 0.1044 - val_loss: 0.1007\n",
      "Epoch 13/100\n",
      "86/86 [==============================] - 3s 37ms/step - loss: 0.0968 - val_loss: 0.0921\n",
      "Epoch 14/100\n",
      "86/86 [==============================] - 3s 39ms/step - loss: 0.0882 - val_loss: 0.0835\n",
      "Epoch 15/100\n",
      "86/86 [==============================] - 3s 38ms/step - loss: 0.0792 - val_loss: 0.0734\n",
      "Epoch 16/100\n",
      "86/86 [==============================] - 3s 33ms/step - loss: 0.0683 - val_loss: 0.0627\n",
      "Epoch 17/100\n",
      "86/86 [==============================] - 3s 34ms/step - loss: 0.0586 - val_loss: 0.0538\n",
      "Epoch 18/100\n",
      "86/86 [==============================] - 3s 34ms/step - loss: 0.0507 - val_loss: 0.0474\n",
      "Epoch 19/100\n",
      "86/86 [==============================] - 3s 34ms/step - loss: 0.0448 - val_loss: 0.0421\n",
      "Epoch 20/100\n",
      "86/86 [==============================] - 3s 39ms/step - loss: 0.0403 - val_loss: 0.0372\n",
      "Epoch 21/100\n",
      "86/86 [==============================] - 3s 34ms/step - loss: 0.0365 - val_loss: 0.0340\n",
      "Epoch 22/100\n",
      "86/86 [==============================] - 3s 34ms/step - loss: 0.0339 - val_loss: 0.0329\n",
      "Epoch 23/100\n",
      "86/86 [==============================] - 3s 33ms/step - loss: 0.0327 - val_loss: 0.0301\n",
      "Epoch 24/100\n",
      "86/86 [==============================] - 3s 33ms/step - loss: 0.0309 - val_loss: 0.0289\n",
      "Epoch 25/100\n",
      "86/86 [==============================] - 3s 33ms/step - loss: 0.0289 - val_loss: 0.0275\n",
      "Epoch 26/100\n",
      "86/86 [==============================] - 3s 33ms/step - loss: 0.0275 - val_loss: 0.0262\n",
      "Epoch 27/100\n",
      "86/86 [==============================] - 3s 33ms/step - loss: 0.0263 - val_loss: 0.0254\n",
      "Epoch 28/100\n",
      "86/86 [==============================] - 3s 33ms/step - loss: 0.0257 - val_loss: 0.0247\n",
      "Epoch 29/100\n",
      "86/86 [==============================] - 3s 36ms/step - loss: 0.0254 - val_loss: 0.0245\n",
      "Epoch 30/100\n",
      "86/86 [==============================] - 4s 42ms/step - loss: 0.0245 - val_loss: 0.0237\n",
      "Epoch 31/100\n",
      "86/86 [==============================] - 3s 37ms/step - loss: 0.0241 - val_loss: 0.0233\n",
      "Epoch 32/100\n",
      "86/86 [==============================] - 3s 32ms/step - loss: 0.0238 - val_loss: 0.0242\n",
      "Epoch 33/100\n",
      "86/86 [==============================] - 3s 33ms/step - loss: 0.0236 - val_loss: 0.0227\n",
      "Epoch 34/100\n",
      "86/86 [==============================] - 3s 32ms/step - loss: 0.0232 - val_loss: 0.0226\n",
      "Epoch 35/100\n",
      "86/86 [==============================] - 3s 32ms/step - loss: 0.0234 - val_loss: 0.0234\n",
      "Epoch 36/100\n",
      "86/86 [==============================] - 3s 32ms/step - loss: 0.0241 - val_loss: 0.0243\n",
      "Epoch 37/100\n",
      "86/86 [==============================] - 3s 35ms/step - loss: 0.0233 - val_loss: 0.0225\n",
      "Epoch 38/100\n",
      "86/86 [==============================] - 3s 34ms/step - loss: 0.0227 - val_loss: 0.0221\n",
      "Epoch 39/100\n",
      "86/86 [==============================] - 3s 33ms/step - loss: 0.0226 - val_loss: 0.0220\n",
      "Epoch 40/100\n",
      "86/86 [==============================] - 3s 34ms/step - loss: 0.0224 - val_loss: 0.0219\n",
      "Epoch 41/100\n",
      "86/86 [==============================] - 3s 34ms/step - loss: 0.0223 - val_loss: 0.0220\n",
      "Epoch 42/100\n",
      "86/86 [==============================] - 3s 33ms/step - loss: 0.0222 - val_loss: 0.0222\n",
      "Epoch 43/100\n",
      "86/86 [==============================] - 3s 33ms/step - loss: 0.0226 - val_loss: 0.0219\n",
      "Epoch 44/100\n",
      "86/86 [==============================] - 3s 33ms/step - loss: 0.0226 - val_loss: 0.0223\n",
      "Epoch 45/100\n",
      "86/86 [==============================] - 3s 34ms/step - loss: 0.0222 - val_loss: 0.0217\n",
      "Epoch 46/100\n",
      "86/86 [==============================] - 3s 37ms/step - loss: 0.0221 - val_loss: 0.0218\n",
      "Epoch 47/100\n",
      "86/86 [==============================] - 4s 44ms/step - loss: 0.0220 - val_loss: 0.0219\n",
      "Epoch 48/100\n",
      "86/86 [==============================] - 4s 46ms/step - loss: 0.0218 - val_loss: 0.0216\n",
      "Epoch 49/100\n",
      "86/86 [==============================] - 4s 48ms/step - loss: 0.0217 - val_loss: 0.0215\n",
      "Epoch 50/100\n",
      "86/86 [==============================] - 5s 53ms/step - loss: 0.0216 - val_loss: 0.0215\n",
      "Epoch 51/100\n",
      "86/86 [==============================] - 4s 52ms/step - loss: 0.0216 - val_loss: 0.0216\n",
      "Epoch 52/100\n",
      "86/86 [==============================] - 4s 48ms/step - loss: 0.0216 - val_loss: 0.0214\n",
      "Epoch 53/100\n",
      "86/86 [==============================] - 4s 47ms/step - loss: 0.0215 - val_loss: 0.0214\n",
      "Epoch 54/100\n",
      "86/86 [==============================] - 4s 52ms/step - loss: 0.0215 - val_loss: 0.0215\n",
      "Epoch 55/100\n",
      "86/86 [==============================] - 4s 52ms/step - loss: 0.0215 - val_loss: 0.0214\n",
      "Epoch 56/100\n",
      "86/86 [==============================] - 4s 49ms/step - loss: 0.0215 - val_loss: 0.0216\n",
      "Epoch 57/100\n",
      "86/86 [==============================] - 3s 37ms/step - loss: 0.0214 - val_loss: 0.0212\n",
      "Epoch 58/100\n",
      "86/86 [==============================] - 3s 35ms/step - loss: 0.0213 - val_loss: 0.0212\n",
      "Epoch 59/100\n",
      "86/86 [==============================] - 3s 34ms/step - loss: 0.0212 - val_loss: 0.0212\n",
      "Epoch 60/100\n",
      "86/86 [==============================] - 3s 34ms/step - loss: 0.0212 - val_loss: 0.0213\n",
      "Epoch 61/100\n",
      "86/86 [==============================] - 3s 34ms/step - loss: 0.0213 - val_loss: 0.0212\n",
      "Epoch 62/100\n",
      "86/86 [==============================] - 3s 35ms/step - loss: 0.0212 - val_loss: 0.0212\n",
      "Epoch 63/100\n",
      "86/86 [==============================] - 3s 39ms/step - loss: 0.0213 - val_loss: 0.0211\n",
      "Epoch 64/100\n",
      "86/86 [==============================] - 4s 42ms/step - loss: 0.0212 - val_loss: 0.0218\n",
      "Epoch 65/100\n",
      "86/86 [==============================] - 4s 42ms/step - loss: 0.0213 - val_loss: 0.0214\n",
      "Epoch 66/100\n",
      "86/86 [==============================] - 3s 36ms/step - loss: 0.0215 - val_loss: 0.0210\n",
      "Epoch 67/100\n",
      "86/86 [==============================] - 3s 37ms/step - loss: 0.0210 - val_loss: 0.0211\n",
      "Epoch 68/100\n",
      "86/86 [==============================] - 3s 35ms/step - loss: 0.0210 - val_loss: 0.0210\n",
      "Epoch 69/100\n",
      "86/86 [==============================] - 3s 36ms/step - loss: 0.0209 - val_loss: 0.0213\n",
      "Epoch 70/100\n",
      "86/86 [==============================] - 3s 34ms/step - loss: 0.0213 - val_loss: 0.0216\n",
      "Epoch 71/100\n",
      "86/86 [==============================] - 3s 36ms/step - loss: 0.0212 - val_loss: 0.0210\n",
      "Epoch 72/100\n",
      "86/86 [==============================] - 3s 35ms/step - loss: 0.0209 - val_loss: 0.0210\n",
      "Epoch 73/100\n",
      "86/86 [==============================] - 4s 43ms/step - loss: 0.0209 - val_loss: 0.0213\n",
      "Epoch 74/100\n",
      "86/86 [==============================] - 4s 43ms/step - loss: 0.0210 - val_loss: 0.0216\n",
      "Epoch 75/100\n",
      "86/86 [==============================] - 4s 42ms/step - loss: 0.0213 - val_loss: 0.0215\n",
      "Epoch 76/100\n",
      "86/86 [==============================] - 3s 38ms/step - loss: 0.0212 - val_loss: 0.0210\n",
      "Epoch 77/100\n",
      "86/86 [==============================] - 3s 36ms/step - loss: 0.0208 - val_loss: 0.0211\n",
      "Epoch 78/100\n",
      "86/86 [==============================] - 4s 45ms/step - loss: 0.0207 - val_loss: 0.0209\n",
      "Epoch 79/100\n",
      "86/86 [==============================] - 4s 46ms/step - loss: 0.0207 - val_loss: 0.0208\n",
      "Epoch 80/100\n",
      "86/86 [==============================] - 4s 44ms/step - loss: 0.0207 - val_loss: 0.0208\n",
      "Epoch 81/100\n",
      "86/86 [==============================] - 3s 40ms/step - loss: 0.0207 - val_loss: 0.0208\n",
      "Epoch 82/100\n",
      "86/86 [==============================] - 4s 44ms/step - loss: 0.0207 - val_loss: 0.0208\n",
      "Epoch 83/100\n",
      "86/86 [==============================] - 4s 42ms/step - loss: 0.0207 - val_loss: 0.0208\n",
      "Epoch 84/100\n",
      "86/86 [==============================] - 3s 40ms/step - loss: 0.0207 - val_loss: 0.0209\n",
      "Epoch 85/100\n",
      "86/86 [==============================] - 4s 45ms/step - loss: 0.0207 - val_loss: 0.0208\n",
      "Epoch 86/100\n",
      "86/86 [==============================] - 4s 50ms/step - loss: 0.0206 - val_loss: 0.0207\n",
      "Epoch 87/100\n",
      "86/86 [==============================] - 4s 45ms/step - loss: 0.0206 - val_loss: 0.0208\n",
      "Epoch 88/100\n",
      "86/86 [==============================] - 4s 44ms/step - loss: 0.0207 - val_loss: 0.0212\n",
      "Epoch 89/100\n",
      "86/86 [==============================] - 4s 41ms/step - loss: 0.0208 - val_loss: 0.0212\n",
      "Epoch 90/100\n",
      "86/86 [==============================] - 4s 43ms/step - loss: 0.0207 - val_loss: 0.0207\n",
      "Epoch 91/100\n",
      "86/86 [==============================] - 4s 42ms/step - loss: 0.0205 - val_loss: 0.0207\n",
      "Epoch 92/100\n",
      "86/86 [==============================] - 4s 50ms/step - loss: 0.0205 - val_loss: 0.0207\n",
      "Epoch 93/100\n",
      "86/86 [==============================] - 4s 43ms/step - loss: 0.0208 - val_loss: 0.0209\n",
      "Epoch 94/100\n",
      "86/86 [==============================] - 4s 45ms/step - loss: 0.0206 - val_loss: 0.0206\n",
      "Epoch 95/100\n",
      "86/86 [==============================] - 4s 43ms/step - loss: 0.0204 - val_loss: 0.0207\n",
      "Epoch 96/100\n",
      "86/86 [==============================] - 4s 42ms/step - loss: 0.0208 - val_loss: 0.0230\n",
      "Epoch 97/100\n",
      "86/86 [==============================] - 3s 37ms/step - loss: 0.0214 - val_loss: 0.0206\n",
      "Epoch 98/100\n",
      "86/86 [==============================] - 3s 36ms/step - loss: 0.0206 - val_loss: 0.0206\n",
      "Epoch 99/100\n",
      "86/86 [==============================] - 3s 39ms/step - loss: 0.0205 - val_loss: 0.0206\n",
      "Epoch 100/100\n",
      "86/86 [==============================] - 3s 36ms/step - loss: 0.0205 - val_loss: 0.0206\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x280e10242e8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dgen = DataGen(HEIGHT, WIDTH, NUM_CHANNEL)\n",
    "x, y = dgen.get_data(path=os.path.abspath(DATA_DIR),\n",
    "                     target_mmc_out=False,\n",
    "                     size=8,\n",
    "                     channel_first=False)\n",
    "\n",
    "x = x / 255.\n",
    "y = y / 255.\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, shuffle=True)\n",
    "\n",
    "autoencoder.fit(x_train, y_train,\n",
    "                epochs=100,\n",
    "                batch_size=10,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs = autoencoder.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 5\n",
    "\n",
    "fig, axes = plt.subplots(figsize=((10, 3)), nrows=1, ncols=NUM_CHANNEL+2)\n",
    "\n",
    "# display input images\n",
    "for i, ax in enumerate(axes.flat[:NUM_CHANNEL]):\n",
    "    ax.imshow(x_test[idx][:, :, i].reshape(HEIGHT, WIDTH), cmap='gray')\n",
    "    ax.axis('off'), ax.set_title('step ' + str(i+1))\n",
    "    \n",
    "# display prediction\n",
    "axes[NUM_CHANNEL].imshow(decoded_imgs[idx][:, :, 0].reshape(HEIGHT, WIDTH), cmap='gray')\n",
    "axes[NUM_CHANNEL].axis('off'), axes[NUM_CHANNEL].set_title('predicted')\n",
    "\n",
    "# display target\n",
    "axes[NUM_CHANNEL+1].imshow(y_test[idx][:, :, 0].reshape(HEIGHT, WIDTH), cmap='gray')\n",
    "axes[NUM_CHANNEL+1].axis('off'), axes[NUM_CHANNEL+1].set_title('target')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
