{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import keras\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Lambda, Reshape, Flatten, ZeroPadding2D, Layer\n",
    "from keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from data_generator import DataGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = './data/data_simple_movement/cartesian/'\n",
    "HEIGHT = 100\n",
    "WIDTH = 100\n",
    "NUM_CHANNEL = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 100, 100, 2)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 100, 100, 16)      304       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 50, 50, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 50, 50, 8)         1160      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 25, 25, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 25, 25, 8)         584       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 13, 13, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 8)         584       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 26, 26, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 26, 26, 8)         584       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 52, 52, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 50, 50, 16)        1168      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 100, 100, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 100, 100, 1)       145       \n",
      "=================================================================\n",
      "Total params: 4,529\n",
      "Trainable params: 4,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_img = Input(shape=(HEIGHT, WIDTH, NUM_CHANNEL))\n",
    "\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 86 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "86/86 [==============================] - 5s 60ms/step - loss: 0.6732 - val_loss: 0.6236\n",
      "Epoch 2/100\n",
      "86/86 [==============================] - 2s 29ms/step - loss: 0.5111 - val_loss: 0.2832\n",
      "Epoch 3/100\n",
      "86/86 [==============================] - 2s 29ms/step - loss: 0.2091 - val_loss: 0.2273\n",
      "Epoch 4/100\n",
      "86/86 [==============================] - 2s 29ms/step - loss: 0.1998 - val_loss: 0.1655\n",
      "Epoch 5/100\n",
      "86/86 [==============================] - 2s 29ms/step - loss: 0.1669 - val_loss: 0.1608\n",
      "Epoch 6/100\n",
      "86/86 [==============================] - 2s 29ms/step - loss: 0.1573 - val_loss: 0.1513\n",
      "Epoch 7/100\n",
      "86/86 [==============================] - 3s 29ms/step - loss: 0.1487 - val_loss: 0.1448\n",
      "Epoch 8/100\n",
      "86/86 [==============================] - 3s 33ms/step - loss: 0.1404 - val_loss: 0.1343\n",
      "Epoch 9/100\n",
      "86/86 [==============================] - 3s 33ms/step - loss: 0.1302 - val_loss: 0.1242\n",
      "Epoch 10/100\n",
      "86/86 [==============================] - 3s 33ms/step - loss: 0.1193 - val_loss: 0.1126\n",
      "Epoch 11/100\n",
      "86/86 [==============================] - 3s 34ms/step - loss: 0.1082 - val_loss: 0.1027\n",
      "Epoch 12/100\n",
      "86/86 [==============================] - 3s 36ms/step - loss: 0.0987 - val_loss: 0.0930\n",
      "Epoch 13/100\n",
      "86/86 [==============================] - 3s 36ms/step - loss: 0.0895 - val_loss: 0.0847\n",
      "Epoch 14/100\n",
      "86/86 [==============================] - 3s 39ms/step - loss: 0.0814 - val_loss: 0.0770\n",
      "Epoch 15/100\n",
      "86/86 [==============================] - 3s 35ms/step - loss: 0.0736 - val_loss: 0.0692\n",
      "Epoch 16/100\n",
      "86/86 [==============================] - 3s 34ms/step - loss: 0.0659 - val_loss: 0.0618\n",
      "Epoch 17/100\n",
      "86/86 [==============================] - 3s 34ms/step - loss: 0.0594 - val_loss: 0.0561\n",
      "Epoch 18/100\n",
      "86/86 [==============================] - 3s 33ms/step - loss: 0.0539 - val_loss: 0.0502\n",
      "Epoch 19/100\n",
      "86/86 [==============================] - 3s 35ms/step - loss: 0.0486 - val_loss: 0.0458\n",
      "Epoch 20/100\n",
      "86/86 [==============================] - 3s 36ms/step - loss: 0.0459 - val_loss: 0.0465\n",
      "Epoch 21/100\n",
      "86/86 [==============================] - 3s 35ms/step - loss: 0.0448 - val_loss: 0.0416\n",
      "Epoch 22/100\n",
      "86/86 [==============================] - 3s 34ms/step - loss: 0.0429 - val_loss: 0.0381\n",
      "Epoch 23/100\n",
      "86/86 [==============================] - 3s 38ms/step - loss: 0.0387 - val_loss: 0.0360\n",
      "Epoch 24/100\n",
      "86/86 [==============================] - 3s 39ms/step - loss: 0.0369 - val_loss: 0.0371\n",
      "Epoch 25/100\n",
      "86/86 [==============================] - 3s 39ms/step - loss: 0.0351 - val_loss: 0.0371\n",
      "Epoch 26/100\n",
      "86/86 [==============================] - 3s 35ms/step - loss: 0.0337 - val_loss: 0.0327\n",
      "Epoch 27/100\n",
      "86/86 [==============================] - 3s 37ms/step - loss: 0.0316 - val_loss: 0.0327\n",
      "Epoch 28/100\n",
      "86/86 [==============================] - 3s 34ms/step - loss: 0.0297 - val_loss: 0.0282\n",
      "Epoch 29/100\n",
      "86/86 [==============================] - 3s 36ms/step - loss: 0.0282 - val_loss: 0.0276\n",
      "Epoch 30/100\n",
      "86/86 [==============================] - 3s 35ms/step - loss: 0.0271 - val_loss: 0.0261\n",
      "Epoch 31/100\n",
      "86/86 [==============================] - 3s 34ms/step - loss: 0.0259 - val_loss: 0.0255\n",
      "Epoch 32/100\n",
      "86/86 [==============================] - 3s 33ms/step - loss: 0.0256 - val_loss: 0.0248\n",
      "Epoch 33/100\n",
      "86/86 [==============================] - 3s 36ms/step - loss: 0.0268 - val_loss: 0.0260\n",
      "Epoch 34/100\n",
      "86/86 [==============================] - 3s 38ms/step - loss: 0.0258 - val_loss: 0.0243\n",
      "Epoch 35/100\n",
      "86/86 [==============================] - 3s 37ms/step - loss: 0.0244 - val_loss: 0.0239\n",
      "Epoch 36/100\n",
      "86/86 [==============================] - 3s 34ms/step - loss: 0.0246 - val_loss: 0.0255\n",
      "Epoch 37/100\n",
      "86/86 [==============================] - 3s 37ms/step - loss: 0.0249 - val_loss: 0.0280\n",
      "Epoch 38/100\n",
      "86/86 [==============================] - 3s 35ms/step - loss: 0.0292 - val_loss: 0.0287\n",
      "Epoch 39/100\n",
      "86/86 [==============================] - 3s 34ms/step - loss: 0.0293 - val_loss: 0.0288\n",
      "Epoch 40/100\n",
      "86/86 [==============================] - 3s 34ms/step - loss: 0.0265 - val_loss: 0.0249\n",
      "Epoch 41/100\n",
      "86/86 [==============================] - 3s 34ms/step - loss: 0.0261 - val_loss: 0.0240\n",
      "Epoch 42/100\n",
      "86/86 [==============================] - 3s 34ms/step - loss: 0.0241 - val_loss: 0.0233\n",
      "Epoch 43/100\n",
      "86/86 [==============================] - 3s 33ms/step - loss: 0.0235 - val_loss: 0.0231\n",
      "Epoch 44/100\n",
      "86/86 [==============================] - 3s 33ms/step - loss: 0.0233 - val_loss: 0.0234\n",
      "Epoch 45/100\n",
      "86/86 [==============================] - 3s 35ms/step - loss: 0.0230 - val_loss: 0.0227\n",
      "Epoch 46/100\n",
      "86/86 [==============================] - 3s 32ms/step - loss: 0.0227 - val_loss: 0.0225\n",
      "Epoch 47/100\n",
      "86/86 [==============================] - 3s 38ms/step - loss: 0.0227 - val_loss: 0.0224\n",
      "Epoch 48/100\n",
      "86/86 [==============================] - 3s 35ms/step - loss: 0.0227 - val_loss: 0.0237\n",
      "Epoch 49/100\n",
      "86/86 [==============================] - 3s 35ms/step - loss: 0.0229 - val_loss: 0.0222\n",
      "Epoch 50/100\n",
      "86/86 [==============================] - 3s 38ms/step - loss: 0.0223 - val_loss: 0.0221\n",
      "Epoch 51/100\n",
      "86/86 [==============================] - 3s 37ms/step - loss: 0.0225 - val_loss: 0.0228\n",
      "Epoch 52/100\n",
      "86/86 [==============================] - 3s 36ms/step - loss: 0.0233 - val_loss: 0.0243\n",
      "Epoch 53/100\n",
      "86/86 [==============================] - 3s 33ms/step - loss: 0.0227 - val_loss: 0.0221\n",
      "Epoch 54/100\n",
      "86/86 [==============================] - 3s 34ms/step - loss: 0.0220 - val_loss: 0.0229\n",
      "Epoch 55/100\n",
      "86/86 [==============================] - 3s 34ms/step - loss: 0.0224 - val_loss: 0.0218\n",
      "Epoch 56/100\n",
      "86/86 [==============================] - 3s 34ms/step - loss: 0.0221 - val_loss: 0.0221\n",
      "Epoch 57/100\n",
      "86/86 [==============================] - 3s 34ms/step - loss: 0.0222 - val_loss: 0.0221\n",
      "Epoch 58/100\n",
      "86/86 [==============================] - 3s 34ms/step - loss: 0.0220 - val_loss: 0.0238\n",
      "Epoch 59/100\n",
      "86/86 [==============================] - 3s 34ms/step - loss: 0.0230 - val_loss: 0.0216\n",
      "Epoch 60/100\n",
      "86/86 [==============================] - 3s 33ms/step - loss: 0.0223 - val_loss: 0.0218\n",
      "Epoch 61/100\n",
      "86/86 [==============================] - 3s 36ms/step - loss: 0.0219 - val_loss: 0.0221\n",
      "Epoch 62/100\n",
      "86/86 [==============================] - 3s 35ms/step - loss: 0.0220 - val_loss: 0.0214\n",
      "Epoch 63/100\n",
      "86/86 [==============================] - 3s 40ms/step - loss: 0.0217 - val_loss: 0.0215\n",
      "Epoch 64/100\n",
      "86/86 [==============================] - 3s 38ms/step - loss: 0.0216 - val_loss: 0.0222\n",
      "Epoch 65/100\n",
      "86/86 [==============================] - 3s 35ms/step - loss: 0.0220 - val_loss: 0.0215\n",
      "Epoch 66/100\n",
      "86/86 [==============================] - 3s 33ms/step - loss: 0.0220 - val_loss: 0.0213\n",
      "Epoch 67/100\n",
      "86/86 [==============================] - 3s 40ms/step - loss: 0.0216 - val_loss: 0.0213\n",
      "Epoch 68/100\n",
      "86/86 [==============================] - 4s 47ms/step - loss: 0.0215 - val_loss: 0.0213\n",
      "Epoch 69/100\n",
      "86/86 [==============================] - 4s 51ms/step - loss: 0.0214 - val_loss: 0.0211\n",
      "Epoch 70/100\n",
      "86/86 [==============================] - 4s 50ms/step - loss: 0.0219 - val_loss: 0.0218\n",
      "Epoch 71/100\n",
      "86/86 [==============================] - 3s 39ms/step - loss: 0.0224 - val_loss: 0.0232\n",
      "Epoch 72/100\n",
      "86/86 [==============================] - 3s 35ms/step - loss: 0.0226 - val_loss: 0.0215\n",
      "Epoch 73/100\n",
      "86/86 [==============================] - 3s 32ms/step - loss: 0.0213 - val_loss: 0.0211\n",
      "Epoch 74/100\n",
      "86/86 [==============================] - 3s 32ms/step - loss: 0.0212 - val_loss: 0.0211\n",
      "Epoch 75/100\n",
      "86/86 [==============================] - 3s 34ms/step - loss: 0.0211 - val_loss: 0.0210\n",
      "Epoch 76/100\n",
      "86/86 [==============================] - 3s 38ms/step - loss: 0.0216 - val_loss: 0.0216\n",
      "Epoch 77/100\n",
      "86/86 [==============================] - 3s 33ms/step - loss: 0.0213 - val_loss: 0.0210\n",
      "Epoch 78/100\n",
      "86/86 [==============================] - 3s 33ms/step - loss: 0.0212 - val_loss: 0.0211\n",
      "Epoch 79/100\n",
      "86/86 [==============================] - 3s 34ms/step - loss: 0.0211 - val_loss: 0.0215\n",
      "Epoch 80/100\n",
      "86/86 [==============================] - 3s 32ms/step - loss: 0.0213 - val_loss: 0.0208\n",
      "Epoch 81/100\n",
      "86/86 [==============================] - 3s 35ms/step - loss: 0.0209 - val_loss: 0.0216\n",
      "Epoch 82/100\n",
      "86/86 [==============================] - 3s 34ms/step - loss: 0.0212 - val_loss: 0.0208\n",
      "Epoch 83/100\n",
      "86/86 [==============================] - 3s 34ms/step - loss: 0.0208 - val_loss: 0.0210\n",
      "Epoch 84/100\n",
      "86/86 [==============================] - 3s 33ms/step - loss: 0.0209 - val_loss: 0.0211\n",
      "Epoch 85/100\n",
      "86/86 [==============================] - 3s 33ms/step - loss: 0.0208 - val_loss: 0.0208\n",
      "Epoch 86/100\n",
      "86/86 [==============================] - 3s 32ms/step - loss: 0.0209 - val_loss: 0.0209\n",
      "Epoch 87/100\n",
      "86/86 [==============================] - 3s 33ms/step - loss: 0.0209 - val_loss: 0.0206\n",
      "Epoch 88/100\n",
      "86/86 [==============================] - 3s 33ms/step - loss: 0.0206 - val_loss: 0.0205\n",
      "Epoch 89/100\n",
      "86/86 [==============================] - 3s 33ms/step - loss: 0.0206 - val_loss: 0.0205\n",
      "Epoch 90/100\n",
      "86/86 [==============================] - 3s 32ms/step - loss: 0.0206 - val_loss: 0.0205\n",
      "Epoch 91/100\n",
      "86/86 [==============================] - 3s 32ms/step - loss: 0.0205 - val_loss: 0.0206\n",
      "Epoch 92/100\n",
      "86/86 [==============================] - 3s 34ms/step - loss: 0.0207 - val_loss: 0.0205\n",
      "Epoch 93/100\n",
      "86/86 [==============================] - 3s 35ms/step - loss: 0.0205 - val_loss: 0.0206\n",
      "Epoch 94/100\n",
      "86/86 [==============================] - 3s 40ms/step - loss: 0.0206 - val_loss: 0.0204\n",
      "Epoch 95/100\n",
      "86/86 [==============================] - 3s 38ms/step - loss: 0.0205 - val_loss: 0.0204\n",
      "Epoch 96/100\n",
      "86/86 [==============================] - 3s 34ms/step - loss: 0.0205 - val_loss: 0.0204\n",
      "Epoch 97/100\n",
      "86/86 [==============================] - 3s 34ms/step - loss: 0.0204 - val_loss: 0.0205\n",
      "Epoch 98/100\n",
      "86/86 [==============================] - 3s 34ms/step - loss: 0.0206 - val_loss: 0.0204\n",
      "Epoch 99/100\n",
      "86/86 [==============================] - 3s 37ms/step - loss: 0.0203 - val_loss: 0.0203\n",
      "Epoch 100/100\n",
      "86/86 [==============================] - 3s 35ms/step - loss: 0.0203 - val_loss: 0.0203\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x221c8e6ee48>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dgen = DataGen(HEIGHT, WIDTH, NUM_CHANNEL)\n",
    "x, y = dgen.get_data(path=os.path.abspath(DATA_DIR),\n",
    "                     target_mmc_out=False,\n",
    "                     size=8,\n",
    "                     channel_first=False)\n",
    "\n",
    "x = x / 255.\n",
    "y = y / 255.\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, shuffle=True)\n",
    "\n",
    "autoencoder.fit(x_train, y_train,\n",
    "                epochs=100,\n",
    "                batch_size=10,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs = autoencoder.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 3  # change index for differnet test image\n",
    "\n",
    "fig, axes = plt.subplots(figsize=((10, 3)), nrows=1, ncols=NUM_CHANNEL+2)\n",
    "\n",
    "# display input images\n",
    "for i, ax in enumerate(axes.flat[:NUM_CHANNEL]):\n",
    "    ax.imshow(x_test[idx][:, :, i].reshape(HEIGHT, WIDTH), cmap='gray')\n",
    "    ax.axis('off'), ax.set_title('step ' + str(i+1))\n",
    "    \n",
    "# display prediction\n",
    "axes[NUM_CHANNEL].imshow(decoded_imgs[idx][:, :, 0].reshape(HEIGHT, WIDTH), cmap='gray')\n",
    "axes[NUM_CHANNEL].axis('off'), axes[NUM_CHANNEL].set_title('predicted')\n",
    "\n",
    "# display target\n",
    "axes[NUM_CHANNEL+1].imshow(y_test[idx][:, :, 0].reshape(HEIGHT, WIDTH), cmap='gray')\n",
    "axes[NUM_CHANNEL+1].axis('off'), axes[NUM_CHANNEL+1].set_title('target')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
